"""
æ›¿ä»£åˆ†ç¾¤æ–¹æ³•æ¨¡çµ„
================
é‡å°3.3ç¯€éšå±¤åˆ†ç¾¤çš„Cophenetic Correlationéä½å•é¡Œï¼Œ
æä¾›ä¸‰ç¨®æ›¿ä»£æ–¹æ³•é€²è¡Œæ¯”è¼ƒ

æ–¹æ³•ï¼š
1. K-means clustering + Silhouette score
2. DBSCAN (åŸºæ–¼å¯†åº¦çš„åˆ†ç¾¤)
3. t-SNEé™ç¶­ + è¦–è¦ºåŒ–æª¢è¦–

ç›®æ¨™ï¼š
- é©—è­‰éšå±¤åˆ†ç¾¤çµæœçš„ç©©å¥æ€§
- æ‰¾å‡ºæ›´é©åˆçš„åˆ†ç¾¤æ–¹æ³•
- ç‚ºå ±å‘Šæä¾›æ–¹æ³•è«–æ¯”è¼ƒ
"""

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    silhouette_score, 
    silhouette_samples,
    adjusted_rand_score,
    calinski_harabasz_score,
    davies_bouldin_score
)
from sklearn.manifold import TSNE
from scipy.cluster.hierarchy import linkage, fcluster
from scipy.spatial.distance import pdist, squareform
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
from pathlib import Path
from typing import Dict, Tuple, List
import logging


class AlternativeClusteringAnalyzer:
    """æ›¿ä»£åˆ†ç¾¤æ–¹æ³•åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.logger = self._setup_logger()
        self.scaler = StandardScaler()
        
    def _setup_logger(self) -> logging.Logger:
        """è¨­å®šæ—¥èªŒè¨˜éŒ„å™¨"""
        logger = logging.getLogger('AlternativeClusteringAnalyzer')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S'
            )
            console_handler.setFormatter(formatter)
            logger.addHandler(console_handler)
        
        return logger
    
    def load_data(self,
                  countries_filepath: str = 'data/raw/CountriesChangePr.csv',
                  cluster_map_filepath: str = 'data/raw/country_cluster_map.csv') -> Tuple[pd.DataFrame, pd.Series, List[str]]:
        """
        è¼‰å…¥ä¸¦æº–å‚™è³‡æ–™
        
        Returns:
        --------
        Tuple[pd.DataFrame, pd.Series, List[str]]
            (æ¨™æº–åŒ–ç‰¹å¾µ, åŸå§‹åˆ†é¡, åœ‹å®¶æ¨™ç±¤)
        """
        self.logger.info("è¼‰å…¥è³‡æ–™...")
        
        # è¼‰å…¥è³‡æ–™
        countries_df = pd.read_csv(countries_filepath, index_col=0)
        cluster_map = pd.read_csv(cluster_map_filepath)
        
        # é¸æ“‡9å€‹é“å¾·ç¶­åº¦çš„AMCEå€¼
        amce_cols = [col for col in countries_df.columns if 'Estimates' in col and 'se' not in col.lower()]
        features_df = countries_df[amce_cols].copy()
        
        # æ¨™æº–åŒ–
        features_scaled = self.scaler.fit_transform(features_df)
        features_scaled_df = pd.DataFrame(
            features_scaled,
            index=features_df.index,
            columns=features_df.columns
        )
        
        # åŸå§‹åˆ†é¡
        cluster_map_indexed = cluster_map.set_index('ISO3')
        original_clusters = cluster_map_indexed.loc[features_df.index, 'Cluster']
        
        # åœ‹å®¶æ¨™ç±¤
        country_labels = features_df.index.tolist()
        
        self.logger.info(f"è³‡æ–™æº–å‚™å®Œæˆï¼š{len(features_scaled_df)} å€‹åœ‹å®¶ï¼Œ{len(amce_cols)} å€‹ç¶­åº¦")
        
        return features_scaled_df, original_clusters, country_labels
    
    # ============================================
    # æ–¹æ³•1: K-means + Silhouette Score
    # ============================================
    
    def kmeans_with_silhouette(self,
                               features_df: pd.DataFrame,
                               k_range: range = range(2, 11)) -> Dict:
        """
        K-meansåˆ†ç¾¤ + Silhouetteè©•ä¼°
        
        Parameters:
        -----------
        features_df : pd.DataFrame
            æ¨™æº–åŒ–ç‰¹å¾µ
        k_range : range
            æ¸¬è©¦çš„kå€¼ç¯„åœ
            
        Returns:
        --------
        Dict
            åˆ†æçµæœ
        """
        self.logger.info("åŸ·è¡ŒK-meansåˆ†ç¾¤...")
        
        results = {
            'k_values': [],
            'silhouette_scores': [],
            'calinski_harabasz_scores': [],
            'davies_bouldin_scores': [],
            'inertias': [],
            'models': {}
        }
        
        for k in k_range:
            self.logger.info(f"  æ¸¬è©¦ k={k}...")
            
            # K-means
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=20)
            labels = kmeans.fit_predict(features_df)
            
            # è©•ä¼°æŒ‡æ¨™
            silhouette = silhouette_score(features_df, labels)
            calinski = calinski_harabasz_score(features_df, labels)
            davies = davies_bouldin_score(features_df, labels)
            inertia = kmeans.inertia_
            
            results['k_values'].append(k)
            results['silhouette_scores'].append(silhouette)
            results['calinski_harabasz_scores'].append(calinski)
            results['davies_bouldin_scores'].append(davies)
            results['inertias'].append(inertia)
            results['models'][k] = kmeans
            
            self.logger.info(f"    Silhouette: {silhouette:.4f}")
            self.logger.info(f"    Calinski-Harabasz: {calinski:.2f}")
            self.logger.info(f"    Davies-Bouldin: {davies:.4f}")
        
        # æ‰¾å‡ºæœ€ä½³k
        best_k_idx = np.argmax(results['silhouette_scores'])
        best_k = results['k_values'][best_k_idx]
        
        self.logger.info(f"\næœ€ä½³ k = {best_k} (Silhouette = {results['silhouette_scores'][best_k_idx]:.4f})")
        
        results['best_k'] = best_k
        results['best_model'] = results['models'][best_k]
        
        return results
    
    def create_kmeans_evaluation_plot(self,
                                     kmeans_results: Dict,
                                     output_path: str = 'outputs/figures/chapter3_exploration/kmeans_evaluation.html') -> str:
        """å»ºç«‹K-meansè©•ä¼°åœ–"""
        self.logger.info("å»ºç«‹K-meansè©•ä¼°åœ–...")
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=(
                'Silhouette Score (è¶Šé«˜è¶Šå¥½)',
                'Calinski-Harabasz Score (è¶Šé«˜è¶Šå¥½)',
                'Davies-Bouldin Score (è¶Šä½è¶Šå¥½)',
                'Elbow Method (æ…£æ€§)'
            ),
            vertical_spacing=0.12,
            horizontal_spacing=0.1
        )
        
        k_values = kmeans_results['k_values']
        
        # Silhouette Score
        fig.add_trace(
            go.Scatter(
                x=k_values,
                y=kmeans_results['silhouette_scores'],
                mode='lines+markers',
                name='Silhouette',
                line=dict(color='blue', width=2),
                marker=dict(size=8)
            ),
            row=1, col=1
        )
        
        # æ¨™è¨»æœ€ä½³k
        best_k = kmeans_results['best_k']
        best_idx = k_values.index(best_k)
        fig.add_annotation(
            x=best_k,
            y=kmeans_results['silhouette_scores'][best_idx],
            text=f"æœ€ä½³ k={best_k}",
            showarrow=True,
            arrowhead=2,
            row=1, col=1
        )
        
        # Calinski-Harabasz Score
        fig.add_trace(
            go.Scatter(
                x=k_values,
                y=kmeans_results['calinski_harabasz_scores'],
                mode='lines+markers',
                name='Calinski-Harabasz',
                line=dict(color='green', width=2),
                marker=dict(size=8),
                showlegend=False
            ),
            row=1, col=2
        )
        
        # Davies-Bouldin Score (è¶Šä½è¶Šå¥½)
        fig.add_trace(
            go.Scatter(
                x=k_values,
                y=kmeans_results['davies_bouldin_scores'],
                mode='lines+markers',
                name='Davies-Bouldin',
                line=dict(color='red', width=2),
                marker=dict(size=8),
                showlegend=False
            ),
            row=2, col=1
        )
        
        # Elbow Method
        fig.add_trace(
            go.Scatter(
                x=k_values,
                y=kmeans_results['inertias'],
                mode='lines+markers',
                name='Inertia',
                line=dict(color='orange', width=2),
                marker=dict(size=8),
                showlegend=False
            ),
            row=2, col=2
        )
        
        fig.update_xaxes(title_text="ç¾¤æ•¸ (k)", row=1, col=1)
        fig.update_xaxes(title_text="ç¾¤æ•¸ (k)", row=1, col=2)
        fig.update_xaxes(title_text="ç¾¤æ•¸ (k)", row=2, col=1)
        fig.update_xaxes(title_text="ç¾¤æ•¸ (k)", row=2, col=2)
        
        fig.update_layout(
            title_text='K-meansåˆ†ç¾¤ï¼šè©•ä¼°æŒ‡æ¨™æ¯”è¼ƒ',
            font=dict(family="Arial, sans-serif", size=12),
            title_font_size=18,
            title_x=0.5,
            height=800
        )
        
        # å„²å­˜
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        fig.write_html(output_path)
        self.logger.info(f"K-meansè©•ä¼°åœ–å·²å„²å­˜: {output_path}")
        
        return output_path
    
    # ============================================
    # æ–¹æ³•2: DBSCAN
    # ============================================
    
    def dbscan_clustering(self,
                         features_df: pd.DataFrame,
                         eps_range: List[float] = None,
                         min_samples: int = 3) -> Dict:
        """
        DBSCANåˆ†ç¾¤
        
        Parameters:
        -----------
        features_df : pd.DataFrame
            æ¨™æº–åŒ–ç‰¹å¾µ
        eps_range : List[float]
            æ¸¬è©¦çš„epså€¼ç¯„åœ
        min_samples : int
            æœ€å°æ¨£æœ¬æ•¸
            
        Returns:
        --------
        Dict
            åˆ†æçµæœ
        """
        self.logger.info("åŸ·è¡ŒDBSCANåˆ†ç¾¤...")
        
        if eps_range is None:
            # ä½¿ç”¨Kè·é›¢åœ–æ±ºå®šepsç¯„åœ
            distances = pdist(features_df, metric='euclidean')
            distances_sorted = np.sort(distances)
            # é¸æ“‡åˆç†çš„epsç¯„åœ
            eps_range = np.linspace(
                distances_sorted[int(len(distances_sorted)*0.1)],
                distances_sorted[int(len(distances_sorted)*0.5)],
                20
            )
        
        results = {
            'eps_values': [],
            'n_clusters': [],
            'n_noise': [],
            'silhouette_scores': [],
            'models': {}
        }
        
        for eps in eps_range:
            self.logger.info(f"  æ¸¬è©¦ eps={eps:.3f}...")
            
            dbscan = DBSCAN(eps=eps, min_samples=min_samples)
            labels = dbscan.fit_predict(features_df)
            
            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
            n_noise = list(labels).count(-1)
            
            # åªæœ‰ç•¶ç¾¤æ•¸>=2ä¸”æœ‰éå™ªéŸ³é»æ™‚æ‰è¨ˆç®—silhouette
            if n_clusters >= 2 and n_noise < len(labels):
                try:
                    silhouette = silhouette_score(features_df[labels != -1], labels[labels != -1])
                except:
                    silhouette = -1
            else:
                silhouette = -1
            
            results['eps_values'].append(eps)
            results['n_clusters'].append(n_clusters)
            results['n_noise'].append(n_noise)
            results['silhouette_scores'].append(silhouette)
            results['models'][eps] = dbscan
            
            self.logger.info(f"    ç¾¤æ•¸: {n_clusters}, å™ªéŸ³é»: {n_noise}, Silhouette: {silhouette:.4f}")
        
        # æ‰¾å‡ºæœ€ä½³epsï¼ˆsilhouetteæœ€é«˜ä¸”å™ªéŸ³é»åˆç†ï¼‰
        valid_indices = [i for i, s in enumerate(results['silhouette_scores']) if s > 0]
        if valid_indices:
            best_idx = valid_indices[np.argmax([results['silhouette_scores'][i] for i in valid_indices])]
            best_eps = results['eps_values'][best_idx]
            self.logger.info(f"\næœ€ä½³ eps = {best_eps:.3f} (Silhouette = {results['silhouette_scores'][best_idx]:.4f})")
            results['best_eps'] = best_eps
            results['best_model'] = results['models'][best_eps]
        else:
            self.logger.warning("âš ï¸  DBSCANæœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ†ç¾¤")
            results['best_eps'] = None
            results['best_model'] = None
        
        return results
    
    def create_dbscan_evaluation_plot(self,
                                     dbscan_results: Dict,
                                     output_path: str = 'outputs/figures/chapter3_exploration/dbscan_evaluation.html') -> str:
        """å»ºç«‹DBSCANè©•ä¼°åœ–"""
        self.logger.info("å»ºç«‹DBSCANè©•ä¼°åœ–...")
        
        fig = make_subplots(
            rows=1, cols=3,
            subplot_titles=(
                'ç¾¤æ•¸ vs Eps',
                'å™ªéŸ³é»æ•¸ vs Eps',
                'Silhouette Score vs Eps'
            ),
            horizontal_spacing=0.1
        )
        
        eps_values = dbscan_results['eps_values']
        
        # ç¾¤æ•¸
        fig.add_trace(
            go.Scatter(
                x=eps_values,
                y=dbscan_results['n_clusters'],
                mode='lines+markers',
                name='ç¾¤æ•¸',
                line=dict(color='blue', width=2),
                marker=dict(size=8)
            ),
            row=1, col=1
        )
        
        # å™ªéŸ³é»æ•¸
        fig.add_trace(
            go.Scatter(
                x=eps_values,
                y=dbscan_results['n_noise'],
                mode='lines+markers',
                name='å™ªéŸ³é»',
                line=dict(color='red', width=2),
                marker=dict(size=8),
                showlegend=False
            ),
            row=1, col=2
        )
        
        # Silhouette Score
        silhouette_scores_plot = [s if s > 0 else None for s in dbscan_results['silhouette_scores']]
        fig.add_trace(
            go.Scatter(
                x=eps_values,
                y=silhouette_scores_plot,
                mode='lines+markers',
                name='Silhouette',
                line=dict(color='green', width=2),
                marker=dict(size=8),
                showlegend=False
            ),
            row=1, col=3
        )
        
        # æ¨™è¨»æœ€ä½³eps
        if dbscan_results.get('best_eps'):
            best_eps = dbscan_results['best_eps']
            best_idx = eps_values.index(best_eps)
            fig.add_annotation(
                x=best_eps,
                y=dbscan_results['silhouette_scores'][best_idx],
                text=f"æœ€ä½³ eps={best_eps:.2f}",
                showarrow=True,
                arrowhead=2,
                row=1, col=3
            )
        
        fig.update_xaxes(title_text="Eps", row=1, col=1)
        fig.update_xaxes(title_text="Eps", row=1, col=2)
        fig.update_xaxes(title_text="Eps", row=1, col=3)
        
        fig.update_layout(
            title_text='DBSCANåˆ†ç¾¤ï¼šåƒæ•¸è©•ä¼°',
            font=dict(family="Arial, sans-serif", size=12),
            title_font_size=18,
            title_x=0.5,
            height=400
        )
        
        # å„²å­˜
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        fig.write_html(output_path)
        self.logger.info(f"DBSCANè©•ä¼°åœ–å·²å„²å­˜: {output_path}")
        
        return output_path
    
    # ============================================
    # æ–¹æ³•3: t-SNEé™ç¶­è¦–è¦ºåŒ–
    # ============================================
    
    def tsne_visualization(self,
                          features_df: pd.DataFrame,
                          country_labels: List[str],
                          original_clusters: pd.Series,
                          perplexity: int = 30,
                          random_state: int = 42) -> Dict:
        """
        t-SNEé™ç¶­è¦–è¦ºåŒ–
        
        Parameters:
        -----------
        features_df : pd.DataFrame
            æ¨™æº–åŒ–ç‰¹å¾µ
        country_labels : List[str]
            åœ‹å®¶æ¨™ç±¤
        original_clusters : pd.Series
            åŸå§‹åˆ†é¡
        perplexity : int
            t-SNEå›°æƒ‘åº¦åƒæ•¸
        random_state : int
            éš¨æ©Ÿç¨®å­
            
        Returns:
        --------
        Dict
            é™ç¶­çµæœ
        """
        self.logger.info("åŸ·è¡Œt-SNEé™ç¶­...")
        
        # t-SNE
        tsne = TSNE(
            n_components=2,
            perplexity=perplexity,
            random_state=random_state,
            max_iter=1000,
            verbose=1
        )
        
        tsne_results = tsne.fit_transform(features_df)
        
        # å»ºç«‹çµæœDataFrame
        tsne_df = pd.DataFrame({
            'Country': country_labels,
            'tSNE1': tsne_results[:, 0],
            'tSNE2': tsne_results[:, 1],
            'Original_Cluster': original_clusters.values,
            'Cluster_Name': original_clusters.map({
                0: 'Western',
                1: 'Eastern',
                2: 'Southern'
            }).values
        })
        
        self.logger.info("t-SNEé™ç¶­å®Œæˆ")
        
        return {
            'tsne_df': tsne_df,
            'tsne_model': tsne
        }
    
    def create_tsne_plot(self,
                        tsne_results: Dict,
                        kmeans_labels: np.ndarray = None,
                        output_path: str = 'outputs/figures/chapter3_exploration/tsne_visualization.html') -> str:
        """å»ºç«‹t-SNEè¦–è¦ºåŒ–åœ–"""
        self.logger.info("å»ºç«‹t-SNEè¦–è¦ºåŒ–åœ–...")
        
        tsne_df = tsne_results['tsne_df'].copy()
        
        # å¦‚æœæœ‰K-meansæ¨™ç±¤ï¼Œä¹ŸåŠ å…¥
        if kmeans_labels is not None:
            tsne_df['KMeans_Cluster'] = kmeans_labels
        
        # å»ºç«‹åœ–è¡¨ï¼ˆé¡¯ç¤ºåŸå§‹åˆ†é¡ï¼‰
        fig = px.scatter(
            tsne_df,
            x='tSNE1',
            y='tSNE2',
            color='Cluster_Name',
            hover_data=['Country'],
            text='Country',
            title='t-SNEé™ç¶­è¦–è¦ºåŒ–ï¼š130åœ‹é“å¾·è·é›¢',
            color_discrete_map={
                'Western': 'blue',
                'Eastern': 'red',
                'Southern': 'green'
            }
        )
        
        # èª¿æ•´æ–‡å­—é¡¯ç¤º
        fig.update_traces(
            textposition='top center',
            textfont=dict(size=8),
            marker=dict(size=10, line=dict(width=1, color='white'))
        )
        
        fig.update_layout(
            font=dict(family="Arial, sans-serif", size=12),
            title_font_size=18,
            title_x=0.5,
            height=700,
            width=900,
            xaxis_title='t-SNE ç¶­åº¦ 1',
            yaxis_title='t-SNE ç¶­åº¦ 2'
        )
        
        # å„²å­˜
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        fig.write_html(output_path)
        self.logger.info(f"t-SNEè¦–è¦ºåŒ–åœ–å·²å„²å­˜: {output_path}")
        
        return output_path
    
    # ============================================
    # æ–¹æ³•æ¯”è¼ƒ
    # ============================================
    
    def compare_methods(self,
                       features_df: pd.DataFrame,
                       original_clusters: pd.Series,
                       hierarchical_labels: np.ndarray,
                       kmeans_results: Dict,
                       dbscan_results: Dict) -> pd.DataFrame:
        """
        æ¯”è¼ƒå››ç¨®æ–¹æ³•
        
        Returns:
        --------
        pd.DataFrame
            æ¯”è¼ƒè¡¨
        """
        self.logger.info("æ¯”è¼ƒå››ç¨®åˆ†ç¾¤æ–¹æ³•...")
        
        comparison_data = []
        
        # 1. éšå±¤åˆ†ç¾¤
        comparison_data.append({
            'æ–¹æ³•': 'Hierarchical (Ward)',
            'ARI vs åŸå§‹åˆ†é¡': adjusted_rand_score(original_clusters, hierarchical_labels),
            'Silhouette Score': silhouette_score(features_df, hierarchical_labels),
            'ç¾¤æ•¸': len(set(hierarchical_labels)),
            'è©•åƒ¹': 'âŒ Cophenetic Corréä½'
        })
        
        # 2. K-means
        kmeans_labels = kmeans_results['best_model'].labels_
        comparison_data.append({
            'æ–¹æ³•': f'K-means (k={kmeans_results["best_k"]})',
            'ARI vs åŸå§‹åˆ†é¡': adjusted_rand_score(original_clusters, kmeans_labels),
            'Silhouette Score': silhouette_score(features_df, kmeans_labels),
            'ç¾¤æ•¸': kmeans_results['best_k'],
            'è©•åƒ¹': 'âœ… Silhouetteè©•ä¼°æœ€ä½³'
        })
        
        # 3. DBSCAN
        if dbscan_results.get('best_model'):
            dbscan_labels = dbscan_results['best_model'].labels_
            non_noise = dbscan_labels != -1
            if non_noise.sum() > 0:
                ari = adjusted_rand_score(original_clusters[non_noise], dbscan_labels[non_noise])
                sil = silhouette_score(features_df[non_noise], dbscan_labels[non_noise]) if len(set(dbscan_labels[non_noise])) > 1 else -1
                n_clusters = len(set(dbscan_labels)) - 1
                comparison_data.append({
                    'æ–¹æ³•': f'DBSCAN (eps={dbscan_results["best_eps"]:.2f})',
                    'ARI vs åŸå§‹åˆ†é¡': ari,
                    'Silhouette Score': sil,
                    'ç¾¤æ•¸': n_clusters,
                    'è©•åƒ¹': f'âš ï¸  {list(dbscan_labels).count(-1)} å™ªéŸ³é»'
                })
        
        # 4. åŸå§‹åˆ†é¡ï¼ˆåŸºæº–ï¼‰
        comparison_data.append({
            'æ–¹æ³•': 'åŸå§‹åˆ†é¡ (Baseline)',
            'ARI vs åŸå§‹åˆ†é¡': 1.0,
            'Silhouette Score': silhouette_score(features_df, original_clusters),
            'ç¾¤æ•¸': 3,
            'è©•åƒ¹': 'ğŸ“Œ åŸºæº–'
        })
        
        comparison_df = pd.DataFrame(comparison_data)
        
        self.logger.info("\næ–¹æ³•æ¯”è¼ƒçµæœ:")
        print(comparison_df.to_string(index=False))
        
        return comparison_df
    
    def create_comparison_plot(self,
                              comparison_df: pd.DataFrame,
                              output_path: str = 'outputs/figures/chapter3_exploration/clustering_methods_comparison.html') -> str:
        """å»ºç«‹æ–¹æ³•æ¯”è¼ƒåœ–"""
        self.logger.info("å»ºç«‹æ–¹æ³•æ¯”è¼ƒåœ–...")
        
        fig = make_subplots(
            rows=1, cols=2,
            subplot_titles=('ARI vs åŸå§‹åˆ†é¡', 'Silhouette Score'),
            horizontal_spacing=0.15
        )
        
        methods = comparison_df['æ–¹æ³•'].tolist()
        
        # ARI
        fig.add_trace(
            go.Bar(
                x=methods,
                y=comparison_df['ARI vs åŸå§‹åˆ†é¡'],
                name='ARI',
                marker_color='lightblue',
                text=comparison_df['ARI vs åŸå§‹åˆ†é¡'].round(3),
                textposition='outside'
            ),
            row=1, col=1
        )
        
        # Silhouette
        fig.add_trace(
            go.Bar(
                x=methods,
                y=comparison_df['Silhouette Score'],
                name='Silhouette',
                marker_color='lightgreen',
                text=comparison_df['Silhouette Score'].round(3),
                textposition='outside',
                showlegend=False
            ),
            row=1, col=2
        )
        
        fig.update_xaxes(tickangle=-45, row=1, col=1)
        fig.update_xaxes(tickangle=-45, row=1, col=2)
        
        fig.update_yaxes(title_text="ARI", row=1, col=1)
        fig.update_yaxes(title_text="Silhouette Score", row=1, col=2)
        
        fig.update_layout(
            title_text='å››ç¨®åˆ†ç¾¤æ–¹æ³•æ¯”è¼ƒ',
            font=dict(family="Arial, sans-serif", size=12),
            title_font_size=18,
            title_x=0.5,
            height=500
        )
        
        # å„²å­˜
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        fig.write_html(output_path)
        self.logger.info(f"æ–¹æ³•æ¯”è¼ƒåœ–å·²å„²å­˜: {output_path}")
        
        return output_path
    
    # ============================================
    # ä¸»åŸ·è¡Œå‡½æ•¸
    # ============================================
    
    def run_full_analysis(self) -> Dict:
        """åŸ·è¡Œå®Œæ•´çš„æ›¿ä»£æ–¹æ³•åˆ†æ"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("é–‹å§‹æ›¿ä»£åˆ†ç¾¤æ–¹æ³•åˆ†æ...")
        self.logger.info("=" * 60)
        
        # 1. è¼‰å…¥è³‡æ–™
        features_df, original_clusters, country_labels = self.load_data()
        
        # 2. K-means
        self.logger.info("\n" + "=" * 60)
        self.logger.info("ã€æ–¹æ³•1ã€‘K-means + Silhouette")
        self.logger.info("=" * 60)
        kmeans_results = self.kmeans_with_silhouette(features_df)
        kmeans_plot = self.create_kmeans_evaluation_plot(kmeans_results)
        
        # 3. DBSCAN
        self.logger.info("\n" + "=" * 60)
        self.logger.info("ã€æ–¹æ³•2ã€‘DBSCAN")
        self.logger.info("=" * 60)
        dbscan_results = self.dbscan_clustering(features_df)
        dbscan_plot = self.create_dbscan_evaluation_plot(dbscan_results)
        
        # 4. t-SNE
        self.logger.info("\n" + "=" * 60)
        self.logger.info("ã€æ–¹æ³•3ã€‘t-SNEé™ç¶­è¦–è¦ºåŒ–")
        self.logger.info("=" * 60)
        tsne_results = self.tsne_visualization(features_df, country_labels, original_clusters)
        tsne_plot = self.create_tsne_plot(
            tsne_results,
            kmeans_labels=kmeans_results['best_model'].labels_
        )
        
        # 5. å–å¾—éšå±¤åˆ†ç¾¤çµæœï¼ˆå¾3.3ç¯€ï¼‰
        self.logger.info("\n" + "=" * 60)
        self.logger.info("ã€æ¯”è¼ƒã€‘å››ç¨®æ–¹æ³•")
        self.logger.info("=" * 60)
        
        # é‡æ–°åŸ·è¡Œéšå±¤åˆ†ç¾¤ä»¥å–å¾—æ¨™ç±¤
        distance_matrix = pdist(features_df.values, metric='euclidean')
        linkage_matrix = linkage(distance_matrix, method='ward')
        hierarchical_labels = fcluster(linkage_matrix, 3, criterion='maxclust')
        
        # æ¯”è¼ƒæ–¹æ³•
        comparison_df = self.compare_methods(
            features_df,
            original_clusters,
            hierarchical_labels,
            kmeans_results,
            dbscan_results
        )
        
        comparison_plot = self.create_comparison_plot(comparison_df)
        
        # 6. å„²å­˜çµæœ
        output_dir = Path('outputs/tables/chapter3')
        output_dir.mkdir(parents=True, exist_ok=True)
        
        comparison_df.to_csv(
            output_dir / 'clustering_methods_comparison.csv',
            index=False,
            encoding='utf-8-sig'
        )
        
        # å„²å­˜t-SNEçµæœ
        tsne_results['tsne_df'].to_csv(
            output_dir / 'tsne_coordinates.csv',
            index=False,
            encoding='utf-8-sig'
        )
        
        # å„²å­˜K-meansçµæœ
        kmeans_clusters_df = pd.DataFrame({
            'Country': country_labels,
            'KMeans_Cluster': kmeans_results['best_model'].labels_,
            'Original_Cluster': original_clusters.values
        })
        kmeans_clusters_df.to_csv(
            output_dir / 'kmeans_clusters.csv',
            index=False,
            encoding='utf-8-sig'
        )
        
        self.logger.info("\n" + "=" * 60)
        self.logger.info("âœ… æ›¿ä»£åˆ†ç¾¤æ–¹æ³•åˆ†æå®Œæˆï¼")
        self.logger.info("=" * 60)
        
        return {
            'kmeans': kmeans_results,
            'dbscan': dbscan_results,
            'tsne': tsne_results,
            'comparison_df': comparison_df,
            'plots': {
                'kmeans_evaluation': kmeans_plot,
                'dbscan_evaluation': dbscan_plot,
                'tsne_visualization': tsne_plot,
                'methods_comparison': comparison_plot
            }
        }


if __name__ == '__main__':
    analyzer = AlternativeClusteringAnalyzer()
    results = analyzer.run_full_analysis()