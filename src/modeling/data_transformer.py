"""
è³‡æ–™è½‰æ›æ¨¡çµ„ï¼šé¸é …å±¤ç´š â†’ å ´æ™¯å±¤ç´š
=======================================
ç”¨æ–¼ç¬¬5ç« æ©Ÿå™¨å­¸ç¿’åˆ†æçš„è³‡æ–™å‰è™•ç†
æœ¬æ¨¡çµ„å°‡é¸é …å±¤ç´šè³‡æ–™ï¼ˆæ¯å ´æ™¯2è¡Œï¼‰è½‰æ›ç‚ºå ´æ™¯å±¤ç´šè³‡æ–™ï¼ˆæ¯å ´æ™¯1è¡Œï¼‰ï¼Œ
ä¸¦æä¾›ç‰¹å¾µèˆ‡ç›®æ¨™è®Šæ•¸çš„åˆ†é›¢åŠŸèƒ½ã€‚

ç‰ˆæœ¬æ›´æ–° (2024-11-04):
- æ–°å¢ conflict_only åƒæ•¸ï¼Œåªä¿ç•™è¡çªå ´æ™¯ï¼ˆå®ˆæ³• â‰  å¤šæ•¸ï¼‰
- ä¿®æ­£é©—è­‰è¨Šæ¯ï¼Œå€åˆ†ã€Œé æœŸçš„ä¸ä¸€è‡´ã€å’Œã€ŒçœŸæ­£çš„éŒ¯èª¤ã€
"""

import pandas as pd
import numpy as np
from typing import Tuple, List, Optional
import warnings


class SceneLevelTransformer:
    """
    å°‡é¸é …å±¤ç´šè³‡æ–™ï¼ˆæ¯å ´æ™¯2è¡Œï¼‰è½‰æ›ç‚ºå ´æ™¯å±¤ç´šè³‡æ–™ï¼ˆæ¯å ´æ™¯1è¡Œï¼‰
    
    åŸå§‹è³‡æ–™çµæ§‹ï¼š
    - æ¯å€‹ ResponseID å°æ‡‰2è¡Œï¼Œåˆ†åˆ¥æè¿°å…©å€‹é¸é …
    - chose_lawful åœ¨é¸é …å±¤ç´šæ˜¯æŒ‰ (Saved==1) & (is_lawful==1) è¨ˆç®—
    - å› æ­¤åŒä¸€ ResponseID çš„å…©è¡Œ chose_lawful å€¼æœƒä¸åŒï¼ˆé€™æ˜¯é æœŸè¡Œç‚ºï¼‰
    
    è½‰æ›å¾Œçµæ§‹ï¼š
    - æ¯å€‹ ResponseID å°æ‡‰1è¡Œ
    - chose_lawful é‡æ–°è¨ˆç®—ç‚ºã€Œå®ˆæ³•æ–¹æ˜¯å¦è¢«é¸ä¸­ã€
    """
    
    # å ´æ™¯å±¤ç´šè®Šæ•¸ï¼ˆä¸éš¨é¸é …è®ŠåŒ–ï¼‰
    SCENE_LEVEL_VARS = [
        'ResponseID',
        'ExtendedSessionID', 
        'UserID',
        'UserCountry3',
        'ScenarioOrder',
        'ScenarioType',
        'ScenarioTypeStrict',
        'PedPed',
        'DiffNumberOFCharacters',
        'DefaultChoice',
        'NonDefaultChoice',
        'DefaultChoiceIsOmission',
        'Template',
        # ä½¿ç”¨è€…èƒŒæ™¯
        'Review_age',
        'Review_education',
        'Review_gender',
        'Review_income',
        'Review_political',
        'Review_religious',
        # ç›®æ¨™è®Šæ•¸ï¼ˆå°‡è¢«é‡æ–°è¨ˆç®—ï¼‰
        'chose_lawful',
        'chose_majority',
        'lawful_vs_majority_conflict',
        # æ–‡åŒ–åœˆèˆ‡åœ‹å®¶ç‰¹å¾µ
        'Cluster',
        'has_country_features',
        'country_law_preference',
        'country_utilitarian',
        'country_intervention',
        'country_pedestrian_pref',
        'country_gender_pref',
        'country_fitness_pref',
        'country_status_pref',
        'country_age_pref',
        'country_species_pref',
    ]
    
    # éœ€è¦å¾é¸é …å±¤ç´šèšåˆçš„è®Šæ•¸
    OPTION_LEVEL_VARS = [
        'Intervention',  # éœ€è¦å–å®ˆæ³•æ–¹çš„ Intervention å€¼
        'NumberOfCharacters',  # å¯èƒ½éœ€è¦å…©å´çš„äººæ•¸
    ]
    
    def __init__(self, verbose: bool = True):
        """
        åˆå§‹åŒ–è½‰æ›å™¨
        
        Parameters
        ----------
        verbose : bool
            æ˜¯å¦é¡¯ç¤ºè©³ç´°è³‡è¨Š
        """
        self.verbose = verbose
        self.validation_results = {}
        
    def validate_option_level_data(self, data: pd.DataFrame) -> bool:
        """
        é©—è­‰é¸é …å±¤ç´šè³‡æ–™çš„å®Œæ•´æ€§
        
        Parameters
        ----------
        data : pd.DataFrame
            é¸é …å±¤ç´šè³‡æ–™
            
        Returns
        -------
        bool
            é©—è­‰æ˜¯å¦é€šéï¼ˆåƒ…æª¢æŸ¥åš´é‡å•é¡Œï¼‰
        """
        if self.verbose:
            print("=" * 60)
            print("è³‡æ–™é©—è­‰ï¼šé¸é …å±¤ç´šè³‡æ–™å®Œæ•´æ€§æª¢æŸ¥")
            print("=" * 60)
        
        # æª¢æŸ¥1ï¼šæ¯å€‹ ResponseID æ‡‰è©²æœ‰2è¡Œ
        rows_per_response = data.groupby('ResponseID').size()
        valid_responses = rows_per_response[rows_per_response == 2]
        invalid_responses = rows_per_response[rows_per_response != 2]
        
        if self.verbose:
            print(f"\næª¢æŸ¥1ï¼šæ¯å ´æ™¯æ‡‰æœ‰2è¡Œ")
            print(f"  - æœ‰æ•ˆå ´æ™¯æ•¸ï¼ˆ2è¡Œï¼‰: {len(valid_responses):,}")
            print(f"  - ç„¡æ•ˆå ´æ™¯æ•¸ï¼ˆé2è¡Œï¼‰: {len(invalid_responses):,}")
            if len(invalid_responses) > 0:
                print(f"  - âš ï¸ ç„¡æ•ˆå ´æ™¯è¡Œæ•¸åˆ†ä½ˆ: {invalid_responses.value_counts().to_dict()}")
        
        self.validation_results['valid_responses'] = len(valid_responses)
        self.validation_results['invalid_responses'] = len(invalid_responses)
        
        # æª¢æŸ¥2ï¼šchose_lawful ä¸€è‡´æ€§ï¼ˆåœ¨é¸é …å±¤ç´šé æœŸæœƒä¸ä¸€è‡´ï¼‰
        chose_lawful_check = data.groupby('ResponseID')['chose_lawful'].nunique()
        inconsistent_chose_lawful = chose_lawful_check[chose_lawful_check != 1]
        
        if self.verbose:
            print(f"\næª¢æŸ¥2ï¼šchose_lawful ä¸€è‡´æ€§ï¼ˆé¸é …å±¤ç´šï¼‰")
            print(f"  - ä¸€è‡´çš„å ´æ™¯æ•¸: {(chose_lawful_check == 1).sum():,}")
            print(f"  - ä¸ä¸€è‡´çš„å ´æ™¯æ•¸: {len(inconsistent_chose_lawful):,}")
            if len(inconsistent_chose_lawful) > 0:
                print(f"  - â„¹ï¸ é€™æ˜¯é æœŸè¡Œç‚ºï¼šchose_lawful åœ¨ç‰¹å¾µå·¥ç¨‹æ™‚æŒ‰é¸é …å±¤ç´šè¨ˆç®—")
                print(f"       å¾ŒçºŒå°‡é‡æ–°è¨ˆç®—æ­£ç¢ºçš„å ´æ™¯å±¤ç´šç›®æ¨™è®Šæ•¸")
        
        self.validation_results['consistent_chose_lawful'] = (chose_lawful_check == 1).sum()
        self.validation_results['inconsistent_chose_lawful'] = len(inconsistent_chose_lawful)
        
        # æª¢æŸ¥3ï¼šis_lawful åœ¨åŒä¸€ ResponseID æ‡‰è©²æœ‰0å’Œ1å„ä¸€å€‹
        if 'is_lawful' in data.columns:
            is_lawful_check = data.groupby('ResponseID')['is_lawful'].apply(
                lambda x: set(x) == {0, 1}
            )
            valid_is_lawful = is_lawful_check.sum()
            
            if self.verbose:
                print(f"\næª¢æŸ¥3ï¼šis_lawful é…å°å®Œæ•´æ€§")
                print(f"  - å®Œæ•´é…å°ï¼ˆ0,1å„ä¸€ï¼‰: {valid_is_lawful:,}")
                print(f"  - ä¸å®Œæ•´é…å°: {(~is_lawful_check).sum():,}")
            
            self.validation_results['valid_is_lawful_pairs'] = valid_is_lawful
        
        # ç¸½çµé©—è­‰çµæœï¼ˆåªæœ‰å ´æ™¯è¡Œæ•¸ä¸å°æ‰æ˜¯åš´é‡å•é¡Œï¼‰
        critical_issues = len(invalid_responses) > 0
        
        if self.verbose:
            if critical_issues:
                print(f"\né©—è­‰çµæœ: âŒ æœ‰åš´é‡å•é¡Œï¼ˆéƒ¨åˆ†å ´æ™¯è¡Œæ•¸ä¸å°ï¼‰")
            else:
                print(f"\né©—è­‰çµæœ: âœ… é€šé")
            print("=" * 60)
        
        return not critical_issues
    
    def transform(
        self, 
        data: pd.DataFrame,
        exclude_unclassified: bool = True,
        conflict_only: bool = True,
        add_intervention_feature: bool = True
    ) -> pd.DataFrame:
        """
        å°‡é¸é …å±¤ç´šè³‡æ–™ï¼ˆæ¯å ´æ™¯2è¡Œï¼‰è½‰æ›ç‚ºå ´æ™¯å±¤ç´šè³‡æ–™ï¼ˆæ¯å ´æ™¯1è¡Œï¼‰
        
        Parameters
        ----------
        data : pd.DataFrame
            é¸é …å±¤ç´šè³‡æ–™
        exclude_unclassified : bool
            æ˜¯å¦æ’é™¤ Cluster == -1 çš„æœªåˆ†é¡åœ‹å®¶
        conflict_only : bool
            æ˜¯å¦åªä¿ç•™è¡çªå ´æ™¯ï¼ˆå®ˆæ³• â‰  å¤šæ•¸ï¼‰
            True = åªä¿ç•™ã€Œå®ˆæ³•å°‘æ•¸ vs. é•æ³•å¤šæ•¸ã€çš„é“å¾·å…©é›£å ´æ™¯
            False = ä¿ç•™æ‰€æœ‰å ´æ™¯
        add_intervention_feature : bool
            æ˜¯å¦æ·»åŠ  Intervention ç‰¹å¾µï¼ˆå®ˆæ³•æ–¹æ˜¯å¦éœ€è¦ä»‹å…¥ï¼‰
            
        Returns
        -------
        pd.DataFrame
            å ´æ™¯å±¤ç´šè³‡æ–™
        """
        if self.verbose:
            print("\n" + "=" * 60)
            print("è³‡æ–™è½‰æ›ï¼šé¸é …å±¤ç´š â†’ å ´æ™¯å±¤ç´š")
            print("=" * 60)
            print(f"è¼¸å…¥è³‡æ–™: {len(data):,} è¡Œï¼ˆé¸é …å±¤ç´šï¼‰")
            print(f"\nè½‰æ›è¨­å®š:")
            print(f"  - exclude_unclassified: {exclude_unclassified}")
            print(f"  - conflict_only: {conflict_only}")
            print(f"  - add_intervention_feature: {add_intervention_feature}")
        
        # å…ˆé©—è­‰è³‡æ–™
        self.validate_option_level_data(data)
        
        # è¤‡è£½è³‡æ–™é¿å…ä¿®æ”¹åŸå§‹è³‡æ–™
        df = data.copy()
        
        # æ’é™¤æœªåˆ†é¡åœ‹å®¶
        if exclude_unclassified and 'Cluster' in df.columns:
            before_filter = len(df)
            df = df[df['Cluster'] != -1]
            if self.verbose:
                print(f"\næ’é™¤ Cluster == -1: {before_filter:,} â†’ {len(df):,} è¡Œ")
        
        # åªä¿ç•™è¡çªå ´æ™¯ï¼ˆå®ˆæ³• â‰  å¤šæ•¸ï¼‰
        if conflict_only and 'lawful_vs_majority_conflict' in df.columns:
            before_conflict = len(df)
            # è¡çªå ´æ™¯ï¼šå®ˆæ³•æ–¹æ˜¯å°‘æ•¸ï¼Œé•æ³•æ–¹æ˜¯å¤šæ•¸
            df = df[df['lawful_vs_majority_conflict'] == 1]
            if self.verbose:
                print(f"åªä¿ç•™è¡çªå ´æ™¯: {before_conflict:,} â†’ {len(df):,} è¡Œ")
                print(f"  ï¼ˆç¯©é¸æ¢ä»¶: lawful_vs_majority_conflict == 1ï¼‰")
                print(f"  ï¼ˆæ„ç¾©: å®ˆæ³•å°‘æ•¸ vs. é•æ³•å¤šæ•¸ çš„é“å¾·å…©é›£ï¼‰")
        
        # åªä¿ç•™æœ‰æ•ˆå ´æ™¯ï¼ˆæ¯å€‹ ResponseID æœ‰2è¡Œï¼‰
        rows_per_response = df.groupby('ResponseID').size()
        valid_response_ids = rows_per_response[rows_per_response == 2].index
        df = df[df['ResponseID'].isin(valid_response_ids)]
        
        if self.verbose:
            print(f"ä¿ç•™æœ‰æ•ˆå ´æ™¯ï¼ˆ2è¡Œï¼‰: {len(df):,} è¡Œ")
        
        # ========================================
        # ğŸ”§ é—œéµï¼šé‡æ–°è¨ˆç®—å ´æ™¯å±¤ç´šçš„ chose_lawful å’Œ chose_majority
        # ========================================
        if self.verbose:
            print("\né‡æ–°è¨ˆç®—å ´æ™¯å±¤ç´šçš„ç›®æ¨™è®Šæ•¸...")
        
        # chose_lawful: æ‰¾åˆ°å®ˆæ³•æ–¹(is_lawful=1)çš„ Saved å€¼
        # æ„ç¾©ï¼šä½¿ç”¨è€…æ˜¯å¦é¸æ“‡æ‹¯æ•‘å®ˆæ³•æ–¹ï¼ˆå³ä½¿ä»–å€‘æ˜¯å°‘æ•¸ï¼‰
        scene_chose_lawful = df[df['is_lawful'] == 1].groupby('ResponseID')['Saved'].first()
        scene_chose_lawful = scene_chose_lawful.reset_index()
        scene_chose_lawful.columns = ['ResponseID', 'chose_lawful_scene']
        
        # chose_majority: æ‰¾åˆ°å¤šæ•¸æ–¹(is_majority=1)çš„ Saved å€¼
        # æ„ç¾©ï¼šä½¿ç”¨è€…æ˜¯å¦é¸æ“‡æ‹¯æ•‘å¤šæ•¸
        scene_chose_majority = df[df['is_majority'] == 1].groupby('ResponseID')['Saved'].first()
        scene_chose_majority = scene_chose_majority.reset_index()
        scene_chose_majority.columns = ['ResponseID', 'chose_majority_scene']
        
        # ========================================
        
        # ç¢ºå®šå¯ç”¨çš„å ´æ™¯å±¤ç´šè®Šæ•¸ï¼ˆæ’é™¤éœ€è¦é‡æ–°è¨ˆç®—çš„ï¼Œä»¥åŠ ResponseIDï¼‰
        vars_to_exclude = ['chose_lawful', 'chose_majority', 'ResponseID']
        available_scene_vars = [
            col for col in self.SCENE_LEVEL_VARS 
            if col in df.columns and col not in vars_to_exclude
        ]
        
        if self.verbose:
            print(f"\nå¯ç”¨å ´æ™¯å±¤ç´šè®Šæ•¸: {len(available_scene_vars)} å€‹")
        
        # æŒ‰ ResponseID åˆ†çµ„ï¼Œå–ç¬¬ä¸€è¡Œï¼ˆå ´æ™¯å±¤ç´šè®Šæ•¸åœ¨å…©è¡Œç›¸åŒï¼‰
        # ä½¿ç”¨ reset_index() è®“ ResponseID æˆç‚ºæ¬„ä½
        scene_data = df.groupby('ResponseID')[available_scene_vars].first().reset_index()
        
        # åˆä½µæ­£ç¢ºçš„ chose_lawful å’Œ chose_majority
        scene_data = scene_data.merge(scene_chose_lawful, on='ResponseID', how='left')
        scene_data = scene_data.merge(scene_chose_majority, on='ResponseID', how='left')
        
        # é‡å‘½åç‚ºæ¨™æº–æ¬„ä½åä¸¦è½‰æ›ç‚ºæ•´æ•¸
        scene_data['chose_lawful'] = scene_data['chose_lawful_scene'].astype(int)
        scene_data['chose_majority'] = scene_data['chose_majority_scene'].astype(int)
        scene_data = scene_data.drop(columns=['chose_lawful_scene', 'chose_majority_scene'])
        
        # è¨ˆç®—çµ±è¨ˆ
        lawful_rate = scene_data['chose_lawful'].mean()
        majority_rate = scene_data['chose_majority'].mean()
        
        if self.verbose:
            print(f"\nä¿®æ­£å¾Œç›®æ¨™è®Šæ•¸çµ±è¨ˆ:")
            print(f"  - chose_lawful=0 (é¸æ•ˆç›Š/å¤šæ•¸): {(scene_data['chose_lawful']==0).sum():,}")
            print(f"  - chose_lawful=1 (é¸å®ˆæ³•/å°‘æ•¸): {(scene_data['chose_lawful']==1).sum():,}")
            print(f"  - å®ˆæ³•é¸æ“‡ç‡: {lawful_rate*100:.1f}%")
            print(f"  - å¤šæ•¸é¸æ“‡ç‡: {majority_rate*100:.1f}%")
            
            # é©—è­‰ï¼šåœ¨è¡çªå ´æ™¯ä¸­ï¼Œchose_lawful + chose_majority æ‡‰è©² = 1
            if conflict_only:
                both_check = scene_data['chose_lawful'] + scene_data['chose_majority']
                if (both_check == 1).all():
                    print(f"  âœ… é©—è­‰é€šé: chose_lawful + chose_majority = 1ï¼ˆäº’æ–¥ï¼‰")
                else:
                    print(f"  âš ï¸ é©—è­‰ç•°å¸¸: æœ‰ {(both_check != 1).sum()} ç­†ä¸ç¬¦åˆäº’æ–¥æ¢ä»¶")
        
        # æ·»åŠ  Intervention ç‰¹å¾µï¼šå®ˆæ³•æ–¹æ˜¯å¦éœ€è¦ä»‹å…¥æ‰èƒ½æ‹¯æ•‘
        if add_intervention_feature and 'is_lawful' in df.columns and 'Intervention' in df.columns:
            lawful_intervention = df[df['is_lawful'] == 1].groupby('ResponseID')['Intervention'].first()
            lawful_intervention = lawful_intervention.reset_index()
            lawful_intervention.columns = ['ResponseID', 'lawful_requires_intervention']
            
            scene_data = scene_data.merge(lawful_intervention, on='ResponseID', how='left')
            
            if self.verbose:
                intervention_rate = scene_data['lawful_requires_intervention'].mean()
                print(f"\næ·»åŠ ç‰¹å¾µ: lawful_requires_intervention")
                print(f"  - éœ€è¦ä»‹å…¥æ‰èƒ½æ•‘å®ˆæ³•æ–¹çš„æ¯”ä¾‹: {intervention_rate*100:.1f}%")
        
        if self.verbose:
            print(f"\nè¼¸å‡ºè³‡æ–™: {len(scene_data):,} è¡Œï¼ˆå ´æ™¯å±¤ç´šï¼‰")
            print(f"æ¬„ä½æ•¸: {len(scene_data.columns)}")
            print("=" * 60)
        
        return scene_data
    
    def get_feature_target_split(
        self, 
        scene_data: pd.DataFrame,
        target_col: str = 'chose_lawful',
        feature_cols: Optional[List[str]] = None
    ) -> Tuple[pd.DataFrame, pd.Series]:
        """
        åˆ†é›¢ç‰¹å¾µèˆ‡ç›®æ¨™è®Šæ•¸
        
        Parameters
        ----------
        scene_data : pd.DataFrame
            å ´æ™¯å±¤ç´šè³‡æ–™
        target_col : str
            ç›®æ¨™è®Šæ•¸æ¬„ä½å
        feature_cols : List[str], optional
            ç‰¹å¾µæ¬„ä½åˆ—è¡¨ï¼Œè‹¥ç‚º None å‰‡ä½¿ç”¨é è¨­ç‰¹å¾µ
            
        Returns
        -------
        Tuple[pd.DataFrame, pd.Series]
            (ç‰¹å¾µ DataFrame, ç›®æ¨™ Series)
        """
        if feature_cols is None:
            # é è¨­ç‰¹å¾µçµ„åˆï¼ˆæ ¹æ“šçŸ¥è­˜åº«è¨­è¨ˆï¼‰
            feature_cols = [
                # å ´æ™¯çµæ§‹
                'DiffNumberOFCharacters',
                'PedPed',
                # ä½¿ç”¨è€…ç‰¹å¾µ
                'Review_age',
                'Review_political',
                'Review_religious',
                # æ–‡åŒ–åœˆï¼ˆå°‡é€²è¡Œ One-Hot ç·¨ç¢¼ï¼‰
                'Cluster',
                # åœ‹å®¶å±¤ç´šç‰¹å¾µ
                'country_law_preference',
                'country_utilitarian',
            ]
            
            # æ·»åŠ  Intervention ç‰¹å¾µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'lawful_requires_intervention' in scene_data.columns:
                feature_cols.append('lawful_requires_intervention')
        
        # éæ¿¾å¯ç”¨ç‰¹å¾µ
        available_features = [col for col in feature_cols if col in scene_data.columns]
        
        if self.verbose:
            print(f"\nç‰¹å¾µé¸æ“‡:")
            print(f"  - è«‹æ±‚ç‰¹å¾µ: {len(feature_cols)} å€‹")
            print(f"  - å¯ç”¨ç‰¹å¾µ: {len(available_features)} å€‹")
            missing = set(feature_cols) - set(available_features)
            if missing:
                print(f"  - ç¼ºå¤±ç‰¹å¾µ: {missing}")
        
        X = scene_data[available_features].copy()
        y = scene_data[target_col].copy()
        
        return X, y


def prepare_features_for_xgboost(
    X: pd.DataFrame,
    cluster_onehot: bool = True
) -> pd.DataFrame:
    """
    ç‚º XGBoost æº–å‚™ç‰¹å¾µï¼ˆOne-Hot ç·¨ç¢¼ç­‰ï¼‰
    
    Parameters
    ----------
    X : pd.DataFrame
        åŸå§‹ç‰¹å¾µ DataFrame
    cluster_onehot : bool
        æ˜¯å¦å° Cluster é€²è¡Œ One-Hot ç·¨ç¢¼
        
    Returns
    -------
    pd.DataFrame
        è™•ç†å¾Œçš„ç‰¹å¾µ DataFrame
    """
    X_processed = X.copy()
    
    # Cluster One-Hot ç·¨ç¢¼
    if cluster_onehot and 'Cluster' in X_processed.columns:
        # å‰µå»ºè™›æ“¬è®Šæ•¸ï¼Œä»¥ Western (0) ç‚ºåƒç…§çµ„
        cluster_dummies = pd.get_dummies(
            X_processed['Cluster'], 
            prefix='Cluster',
            drop_first=False  # ä¿ç•™æ‰€æœ‰é¡åˆ¥ï¼Œä¾¿æ–¼ SHAP è§£é‡‹
        )
        # é‡å‘½åç‚ºæ›´æœ‰æ„ç¾©çš„åç¨±
        cluster_dummies.columns = [
            'Cluster_Western' if c == 'Cluster_0' else
            'Cluster_Eastern' if c == 'Cluster_1' else
            'Cluster_Southern' if c == 'Cluster_2' else c
            for c in cluster_dummies.columns
        ]
        
        # ç§»é™¤åŸå§‹ Cluster æ¬„ä½ï¼Œæ·»åŠ è™›æ“¬è®Šæ•¸
        X_processed = X_processed.drop(columns=['Cluster'])
        X_processed = pd.concat([X_processed, cluster_dummies], axis=1)
    
    return X_processed


# ä¾¿åˆ©å‡½æ•¸
def load_and_transform_data(
    train_path: str,
    test_path: str,
    conflict_only: bool = True,
    verbose: bool = True
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    è¼‰å…¥ä¸¦è½‰æ›è¨“ç·´é›†èˆ‡æ¸¬è©¦é›†
    
    Parameters
    ----------
    train_path : str
        è¨“ç·´é›†è·¯å¾‘
    test_path : str
        æ¸¬è©¦é›†è·¯å¾‘
    conflict_only : bool
        æ˜¯å¦åªä¿ç•™è¡çªå ´æ™¯ï¼ˆé è¨­ Trueï¼‰
    verbose : bool
        æ˜¯å¦é¡¯ç¤ºè©³ç´°è³‡è¨Š
        
    Returns
    -------
    Tuple[pd.DataFrame, pd.DataFrame]
        (è¨“ç·´é›†å ´æ™¯å±¤ç´š, æ¸¬è©¦é›†å ´æ™¯å±¤ç´š)
    """
    transformer = SceneLevelTransformer(verbose=verbose)
    
    # è¼‰å…¥è³‡æ–™
    if verbose:
        print("è¼‰å…¥è¨“ç·´é›†...")
    train_data = pd.read_csv(train_path)
    
    if verbose:
        print("è¼‰å…¥æ¸¬è©¦é›†...")
    test_data = pd.read_csv(test_path)
    
    # è½‰æ›
    if verbose:
        print("\n" + "=" * 60)
        print("è½‰æ›è¨“ç·´é›†")
    train_scene = transformer.transform(train_data, conflict_only=conflict_only)
    
    if verbose:
        print("\n" + "=" * 60)
        print("è½‰æ›æ¸¬è©¦é›†")
    test_scene = transformer.transform(test_data, conflict_only=conflict_only)
    
    return train_scene, test_scene


if __name__ == "__main__":
    # æ¸¬è©¦ç¨‹å¼ç¢¼
    print("è³‡æ–™è½‰æ›æ¨¡çµ„æ¸¬è©¦")
    print("è«‹ä½¿ç”¨ load_and_transform_data() å‡½æ•¸è¼‰å…¥ä¸¦è½‰æ›è³‡æ–™")