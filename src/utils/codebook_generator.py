"""
è³‡æ–™å­—å…¸ï¼ˆCodebookï¼‰è‡ªå‹•ç”Ÿæˆå™¨
è‡ªå‹•æƒæCSVæª”æ¡ˆä¸¦ç”Ÿæˆç¹é«”ä¸­æ–‡èªªæ˜æ–‡ä»¶
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Any
import json
from datetime import datetime

class CodebookGenerator:
    """ç”Ÿæˆè³‡æ–™å­—å…¸çš„å·¥å…·é¡åˆ¥"""

    def __init__(self, data_dir: str = 'data/raw'):
        """
        åˆå§‹åŒ–Codebookç”Ÿæˆå™¨

        Parameters:
        -----------
        data_dir : str
            åŸå§‹è³‡æ–™ç›®éŒ„è·¯å¾‘
        """
        self.data_dir = Path(data_dir)
        self.codebook_data = {}

        # æ¬„ä½ä¸­æ–‡èªªæ˜å°ç…§è¡¨ï¼ˆMIT Moral Machineå°ˆç”¨ï¼‰
        self.field_descriptions = {
            # é€šç”¨æ¬„ä½
            'Unnamed: 0': 'è³‡æ–™åˆ—ç´¢å¼•ï¼ˆç”±pandasè‡ªå‹•ç”Ÿæˆï¼‰',
            '': 'è³‡æ–™åˆ—ç´¢å¼•æˆ–åœ‹å®¶ä»£ç¢¼',
            
            # è­˜åˆ¥æ¬„ä½
            'ResponseID': 'å ´æ™¯å”¯ä¸€è­˜åˆ¥ç¢¼',
            'ExtendedSessionID': 'å®Œæ•´Sessionè­˜åˆ¥ç¢¼ï¼ˆå«UserIDï¼‰',
            'UserID': 'ä½¿ç”¨è€…å”¯ä¸€è­˜åˆ¥ç¢¼ï¼ˆç€è¦½å™¨æŒ‡ç´‹ï¼‰',
            'UserCountry3': 'ä½¿ç”¨è€…æ‰€åœ¨åœ‹å®¶ï¼ˆISO 3166-1 alpha-3ä»£ç¢¼ï¼‰',

            # å ´æ™¯è¨­è¨ˆæ¬„ä½
            'ScenarioOrder': 'å ´æ™¯åœ¨Sessionä¸­çš„é †åºï¼ˆ1-13ï¼‰',
            'ScenarioType': 'å ´æ™¯é¡å‹ï¼ˆUtilitarian/Gender/Ageç­‰ï¼‰',
            'ScenarioTypeStrict': 'åš´æ ¼å ´æ™¯é¡å‹åˆ†é¡',
            'AttributeLevel': 'è©²çµæœçš„å±¬æ€§å±¤ç´š',

            # æ±ºç­–ç›¸é—œæ¬„ä½
            'Saved': 'è©²çµæœæ˜¯å¦è¢«é¸æ“‡æ‹¯æ•‘ï¼ˆ1=æ˜¯, 0=å¦ï¼‰',
            'Intervention': 'è»Šè¼›æ˜¯å¦ä»‹å…¥ï¼ˆ0=ç¶­æŒåŸè·¯ç·š, 1=è½‰å‘ï¼‰',
            'PedPed': 'æ˜¯å¦ç‚ºè¡Œäººvs.è¡Œäººï¼ˆ1=æ˜¯, 0=è¡Œäººvs.ä¹˜å®¢ï¼‰',
            'Barrier': 'è©²å´æ˜¯å¦æœ‰éšœç¤™ç‰©ï¼ˆ1=ä¹˜å®¢, 0=è¡Œäººï¼‰',
            'CrossingSignal': 'éé¦¬è·¯çš„åˆæ³•æ€§ï¼ˆ0=ç„¡, 1=ç¶ ç‡ˆåˆæ³•, 2=ç´…ç‡ˆé•æ³•ï¼‰',
            'NumberOfCharacters': 'è©²å´çš„è§’è‰²æ•¸é‡ï¼ˆ1-5ï¼‰',
            'DiffNumberOFCharacters': 'å…©å´äººæ•¸å·®ç•°ï¼ˆ0-4ï¼‰',

            # é è¨­é¸æ“‡ç›¸é—œ
            'DefaultChoice': 'é è¨­é¸æ“‡ï¼ˆMales/Young/Fit/High/Hoomans/Moreï¼‰',
            'NonDefaultChoice': 'éé è¨­é¸æ“‡ï¼ˆFemales/Old/Fat/Low/Pets/Lessï¼‰',
            'DefaultChoiceIsOmission': 'é è¨­é¸æ“‡æ˜¯å¦ç‚ºä¸ä»‹å…¥ï¼ˆ1=æ˜¯, 0=å¦ï¼‰',

            # äººå£çµ±è¨ˆæ¬„ä½
            'Review_age': 'ä½¿ç”¨è€…å¹´é½¡ï¼ˆ18-75ï¼‰',
            'Review_gender': 'ä½¿ç”¨è€…æ€§åˆ¥ï¼ˆmale/female/otherï¼‰',
            'Review_education': 'æœ€é«˜æ•™è‚²ç¨‹åº¦',
            'Review_income': 'å¹´æ”¶å…¥ï¼ˆç¾é‡‘ï¼‰',
            'Review_political': 'æ”¿æ²»ç«‹å ´ï¼ˆ0=ä¿å®ˆ, 1=é€²æ­¥ï¼‰',
            'Review_religious': 'å®—æ•™è™”èª åº¦ï¼ˆ0=ä¸è™”èª , 1=è™”èª ï¼‰',

            # æŠ€è¡“æ¬„ä½
            'Template': 'ä½¿ç”¨è£ç½®é¡å‹ï¼ˆdesktop/mobile/tabletï¼‰',
            'DescriptionShown': 'æ˜¯å¦é»æ“ŠæŸ¥çœ‹å ´æ™¯æè¿°ï¼ˆ1=æ˜¯, 0=å¦ï¼‰',
            'LeftHand': 'è©²çµæœé¡¯ç¤ºä½ç½®ï¼ˆ1=å·¦å´, 0=å³å´ï¼‰',

            # CountriesChangePr.csv æ¬„ä½ - Estimates (å¹³å‡é‚Šéš›å› æœæ•ˆæ‡‰ä¼°è¨ˆå€¼)
            '[Omission -> Commission]: Estimates': 'ä¸ä½œç‚ºâ†’ä½œç‚º(ä»‹å…¥åå¥½) - AMCEä¼°è¨ˆå€¼',
            '[Passengers -> Pedestrians]: Estimates': 'ä¹˜å®¢â†’è¡Œäºº - AMCEä¼°è¨ˆå€¼',
            'Law [Illegal -> Legal]: Estimates': 'é•æ³•â†’åˆæ³•(å®ˆæ³•åå¥½) - AMCEä¼°è¨ˆå€¼',
            'Gender [Male -> Female]: Estimates': 'ç”·æ€§â†’å¥³æ€§(æ€§åˆ¥åå¥½) - AMCEä¼°è¨ˆå€¼',
            'Fitness [Large -> Fit]: Estimates': 'å¤§å‹é«”å‹â†’å¥å£¯é«”å‹(é«”å‹åå¥½) - AMCEä¼°è¨ˆå€¼',
            'Social Status [Low -> High]: Estimates': 'ä½ç¤¾æœƒåœ°ä½â†’é«˜ç¤¾æœƒåœ°ä½(éšç´šåå¥½) - AMCEä¼°è¨ˆå€¼',
            'Age [Elderly -> Young]: Estimates': 'å¹´é•·â†’å¹´è¼•(å¹´é½¡åå¥½) - AMCEä¼°è¨ˆå€¼',
            'No. Characters [Less -> More]: Estimates': 'è¼ƒå°‘äººæ•¸â†’è¼ƒå¤šäººæ•¸(æ•ˆç›Šä¸»ç¾©æŒ‡æ¨™) - AMCEä¼°è¨ˆå€¼',
            'Species [Pets -> Humans]: Estimates': 'å¯µç‰©â†’äººé¡(ç‰©ç¨®åå¥½) - AMCEä¼°è¨ˆå€¼',
            
            # CountriesChangePr.csv æ¬„ä½ - se (æ¨™æº–èª¤)
            '[Omission -> Commission]: se': 'ä¸ä½œç‚ºâ†’ä½œç‚º(ä»‹å…¥åå¥½) - æ¨™æº–èª¤',
            '[Passengers -> Pedestrians]: se': 'ä¹˜å®¢â†’è¡Œäºº - æ¨™æº–èª¤',
            'Law [Illegal -> Legal]: se': 'é•æ³•â†’åˆæ³•(å®ˆæ³•åå¥½) - æ¨™æº–èª¤',
            'Gender [Male -> Female]: se': 'ç”·æ€§â†’å¥³æ€§(æ€§åˆ¥åå¥½) - æ¨™æº–èª¤',
            'Fitness [Large -> Fit]: se': 'å¤§å‹é«”å‹â†’å¥å£¯é«”å‹(é«”å‹åå¥½) - æ¨™æº–èª¤',
            'Social Status [Low -> High]: se': 'ä½ç¤¾æœƒåœ°ä½â†’é«˜ç¤¾æœƒåœ°ä½(éšç´šåå¥½) - æ¨™æº–èª¤',
            'Age [Elderly -> Young]: se': 'å¹´é•·â†’å¹´è¼•(å¹´é½¡åå¥½) - æ¨™æº–èª¤',
            'No. Characters [Less -> More]: se': 'è¼ƒå°‘äººæ•¸â†’è¼ƒå¤šäººæ•¸(æ•ˆç›Šä¸»ç¾©æŒ‡æ¨™) - æ¨™æº–èª¤',
            'Species [Pets -> Humans]: se': 'å¯µç‰©â†’äººé¡(ç‰©ç¨®åå¥½) - æ¨™æº–èª¤',

            # dendrogram_Culture.csv æ¬„ä½
            'id': 'ç¯€é»è­˜åˆ¥ç¢¼ - æ¨¹ç‹€åœ–çš„å±¤ç´šçµæ§‹ç·¨è™Ÿ',
            'culture': 'æ–‡åŒ–åœˆåç¨± - åœ‹å®¶æ‰€å±¬çš„æ–‡åŒ–é›†ç¾¤',
            'continent': 'æ´²åˆ¥ - åœ°ç†ä½ç½®åˆ†é¡',
            
            # moral_distance.csv æ¬„ä½
            'Country': 'åœ‹å®¶ä»£ç¢¼ - ISO 3166-1 alpha-3æ¨™æº–',
            'Distance': 'é“å¾·è·é›¢å€¼ - è©²åœ‹èˆ‡ç¾åœ‹(åŸºæº–åœ‹)çš„é“å¾·åå¥½å·®ç•°ç¨‹åº¦',

            # countries.csv æ¬„ä½
            'ISO3': 'åœ‹å®¶ä»£ç¢¼(ISO 3166-1 alpha-3)',
            'Country': 'åœ‹å®¶åç¨±(è‹±æ–‡)',  
            'Cluster': 'æ–‡åŒ–é›†ç¾¤ç·¨è™Ÿ(0=Western, 1=Eastern, 2=Southern)',
        }

    def analyze_dataframe(self, df: pd.DataFrame, filename: str) -> Dict[str, Any]:
        """
        åˆ†æå–®ä¸€DataFrameä¸¦ç”Ÿæˆçµ±è¨ˆæ‘˜è¦

        Parameters:
        -----------
        df : pd.DataFrame
            è¦åˆ†æçš„è³‡æ–™æ¡†
        filename : str
            æª”æ¡ˆåç¨±

        Returns:
        --------
        Dict[str, Any]
            åŒ…å«çµ±è¨ˆæ‘˜è¦çš„å­—å…¸
        """
        summary = {
            'æª”æ¡ˆåç¨±': filename,
            'åˆ†ææ™‚é–“': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'è³‡æ–™ç¶­åº¦': {
                'åˆ—æ•¸': len(df),
                'æ¬„æ•¸': len(df.columns),
            },
            'æ¬„ä½è³‡è¨Š': []
        }

        for col in df.columns:
            col_info = self._analyze_column(df[col], col)
            summary['æ¬„ä½è³‡è¨Š'].append(col_info)

        return summary

    def _analyze_column(self, series: pd.Series, col_name: str) -> Dict[str, Any]:
        """
        åˆ†æå–®ä¸€æ¬„ä½

        Parameters:
        -----------
        series : pd.Series
            è¦åˆ†æçš„åºåˆ—
        col_name : str
            æ¬„ä½åç¨±

        Returns:
        --------
        Dict[str, Any]
            æ¬„ä½çµ±è¨ˆè³‡è¨Š
        """
        info = {
            'æ¬„ä½åç¨±': col_name,
            'ä¸­æ–‡èªªæ˜': self.field_descriptions.get(col_name, 'ï¼ˆå¾…è£œå……èªªæ˜ï¼‰'),
            'è³‡æ–™å‹æ…‹': str(series.dtype),
            'ç¼ºå¤±å€¼æ•¸é‡': int(series.isna().sum()),
            'ç¼ºå¤±å€¼æ¯”ä¾‹': f"{series.isna().mean() * 100:.2f}%",
            'å”¯ä¸€å€¼æ•¸é‡': series.nunique(),
        }

        # æ ¹æ“šè³‡æ–™å‹æ…‹æä¾›ä¸åŒçš„çµ±è¨ˆ
        if pd.api.types.is_numeric_dtype(series):
            info.update(self._numeric_stats(series))
        elif pd.api.types.is_object_dtype(series) or pd.api.types.is_categorical_dtype(series):
            info.update(self._categorical_stats(series))

        return info

    def _numeric_stats(self, series: pd.Series) -> Dict[str, Any]:
        """æ•¸å€¼å‹æ¬„ä½çš„çµ±è¨ˆ"""
        valid_data = series.dropna()

        if len(valid_data) == 0:
            return {'çµ±è¨ˆæ‘˜è¦': 'ç„¡æœ‰æ•ˆè³‡æ–™'}

        stats = {
            'çµ±è¨ˆæ‘˜è¦': {
                'å¹³å‡å€¼': f"{valid_data.mean():.4f}",
                'æ¨™æº–å·®': f"{valid_data.std():.4f}",
                'æœ€å°å€¼': f"{valid_data.min():.4f}",
                '25%åˆ†ä½æ•¸': f"{valid_data.quantile(0.25):.4f}",
                'ä¸­ä½æ•¸': f"{valid_data.median():.4f}",
                '75%åˆ†ä½æ•¸': f"{valid_data.quantile(0.75):.4f}",
                'æœ€å¤§å€¼': f"{valid_data.max():.4f}",
            }
        }

        # æª¢æ¸¬ç•°å¸¸å€¼ï¼ˆä½¿ç”¨IQRæ–¹æ³•ï¼‰
        Q1 = valid_data.quantile(0.25)
        Q3 = valid_data.quantile(0.75)
        IQR = Q3 - Q1
        outliers = valid_data[(valid_data < Q1 - 1.5 * IQR) | (valid_data > Q3 + 1.5 * IQR)]

        stats['ç•°å¸¸å€¼è³‡è¨Š'] = {
            'ç•°å¸¸å€¼æ•¸é‡': len(outliers),
            'ç•°å¸¸å€¼æ¯”ä¾‹': f"{len(outliers) / len(valid_data) * 100:.2f}%"
        }

        return stats

    def _categorical_stats(self, series: pd.Series) -> Dict[str, Any]:
        """é¡åˆ¥å‹æ¬„ä½çš„çµ±è¨ˆ"""
        valid_data = series.dropna()

        if len(valid_data) == 0:
            return {'çµ±è¨ˆæ‘˜è¦': 'ç„¡æœ‰æ•ˆè³‡æ–™'}

        # å–å‰10å€‹æœ€å¸¸å‡ºç¾çš„å€¼
        top_values = valid_data.value_counts().head(10)

        stats = {
            'çµ±è¨ˆæ‘˜è¦': {
                'æœ€å¸¸å‡ºç¾å€¼': str(top_values.index[0]) if len(top_values) > 0 else 'N/A',
                'æœ€å¸¸å‡ºç¾æ¬¡æ•¸': int(top_values.iloc[0]) if len(top_values) > 0 else 0,
            },
            'å‰10å€‹å€¼çš„åˆ†ä½ˆ': {
                str(k): {
                    'æ¬¡æ•¸': int(v),
                    'æ¯”ä¾‹': f"{v / len(valid_data) * 100:.2f}%"
                }
                for k, v in top_values.items()
            }
        }

        return stats

    def generate_codebook(self, output_format: str = 'markdown') -> str:
        """
        ç”Ÿæˆæ‰€æœ‰CSVæª”æ¡ˆçš„Codebook

        Parameters:
        -----------
        output_format : str
            è¼¸å‡ºæ ¼å¼ï¼ˆ'markdown', 'excel', 'json'ï¼‰

        Returns:
        --------
        str
            è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        # æƒææ‰€æœ‰CSVæª”æ¡ˆ
        csv_files = list(self.data_dir.glob('*.csv'))

        print(f"æ‰¾åˆ° {len(csv_files)} å€‹CSVæª”æ¡ˆ")

        for csv_file in csv_files:
            print(f"åˆ†æä¸­: {csv_file.name}")

            # è®€å–CSVï¼ˆåªè®€å–å‰10000è¡Œä»¥ç¯€çœè¨˜æ†¶é«”ï¼‰
            try:
                df = pd.read_csv(csv_file, nrows=10000)
                summary = self.analyze_dataframe(df, csv_file.name)
                self.codebook_data[csv_file.name] = summary
            except Exception as e:
                print(f"  éŒ¯èª¤: {e}")
                continue

        # æ ¹æ“šæ ¼å¼è¼¸å‡º
        if output_format == 'markdown':
            return self._generate_markdown()
        elif output_format == 'excel':
            return self._generate_excel()
        elif output_format == 'json':
            return self._generate_json()
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„è¼¸å‡ºæ ¼å¼: {output_format}")

    def _generate_markdown(self) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„Codebook"""
        output_path = self.data_dir.parent / 'metadata' / 'data_dictionary.md'
        output_path.parent.mkdir(exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("# MIT Moral Machine è³‡æ–™å­—å…¸\n\n")
            f.write(f"ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")

            for filename, summary in self.codebook_data.items():
                f.write(f"## {filename}\n\n")
                f.write(f"**è³‡æ–™ç¶­åº¦**ï¼š{summary['è³‡æ–™ç¶­åº¦']['åˆ—æ•¸']} åˆ— Ã— {summary['è³‡æ–™ç¶­åº¦']['æ¬„æ•¸']} æ¬„\n\n")

                f.write("### æ¬„ä½æ¸…å–®\n\n")
                f.write("| æ¬„ä½åç¨± | ä¸­æ–‡èªªæ˜ | è³‡æ–™å‹æ…‹ | ç¼ºå¤±å€¼ | å”¯ä¸€å€¼æ•¸ |\n")
                f.write("|---------|---------|---------|--------|----------|\n")

                for col_info in summary['æ¬„ä½è³‡è¨Š']:
                    f.write(f"| {col_info['æ¬„ä½åç¨±']} | {col_info['ä¸­æ–‡èªªæ˜']} | "
                           f"{col_info['è³‡æ–™å‹æ…‹']} | {col_info['ç¼ºå¤±å€¼æ¯”ä¾‹']} | "
                           f"{col_info['å”¯ä¸€å€¼æ•¸é‡']} |\n")

                f.write("\n### æ¬„ä½è©³ç´°è³‡è¨Š\n\n")

                for col_info in summary['æ¬„ä½è³‡è¨Š']:
                    f.write(f"#### {col_info['æ¬„ä½åç¨±']}\n\n")
                    f.write(f"**ä¸­æ–‡èªªæ˜**ï¼š{col_info['ä¸­æ–‡èªªæ˜']}\n\n")
                    f.write(f"**è³‡æ–™å‹æ…‹**ï¼š{col_info['è³‡æ–™å‹æ…‹']}\n\n")
                    f.write(f"**ç¼ºå¤±å€¼**ï¼š{col_info['ç¼ºå¤±å€¼æ•¸é‡']} ({col_info['ç¼ºå¤±å€¼æ¯”ä¾‹']})\n\n")

                    if 'çµ±è¨ˆæ‘˜è¦' in col_info:
                        if isinstance(col_info['çµ±è¨ˆæ‘˜è¦'], dict):
                            f.write("**çµ±è¨ˆæ‘˜è¦**ï¼š\n\n")
                            for key, value in col_info['çµ±è¨ˆæ‘˜è¦'].items():
                                if isinstance(value, dict):
                                    f.write(f"- {key}ï¼š\n")
                                    for k, v in value.items():
                                        f.write(f"  - {k}ï¼š{v}\n")
                                else:
                                    f.write(f"- {key}ï¼š{value}\n")
                            f.write("\n")

                    if 'å‰10å€‹å€¼çš„åˆ†ä½ˆ' in col_info:
                        f.write("**å‰10å€‹å€¼çš„åˆ†ä½ˆ**ï¼š\n\n")
                        f.write("| å€¼ | æ¬¡æ•¸ | æ¯”ä¾‹ |\n")
                        f.write("|----|------|------|\n")
                        for value, stats in col_info['å‰10å€‹å€¼çš„åˆ†ä½ˆ'].items():
                            f.write(f"| {value} | {stats['æ¬¡æ•¸']} | {stats['æ¯”ä¾‹']} |\n")
                        f.write("\n")

                    f.write("---\n\n")

                f.write("\n\n")

        print(f"âœ… Markdown Codebook å·²ç”Ÿæˆï¼š{output_path}")
        return str(output_path)

    def _generate_excel(self) -> str:
        """ç”ŸæˆExcelæ ¼å¼çš„Codebook"""
        output_path = self.data_dir.parent / 'metadata' / 'data_dictionary.xlsx'
        output_path.parent.mkdir(exist_ok=True)

        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # å»ºç«‹ç¸½è¦½å·¥ä½œè¡¨
            overview_data = []
            for filename, summary in self.codebook_data.items():
                overview_data.append({
                    'æª”æ¡ˆåç¨±': filename,
                    'åˆ—æ•¸': summary['è³‡æ–™ç¶­åº¦']['åˆ—æ•¸'],
                    'æ¬„æ•¸': summary['è³‡æ–™ç¶­åº¦']['æ¬„æ•¸'],
                    'ç¸½ç¼ºå¤±å€¼': sum(col['ç¼ºå¤±å€¼æ•¸é‡'] for col in summary['æ¬„ä½è³‡è¨Š']),
                })

            overview_df = pd.DataFrame(overview_data)
            overview_df.to_excel(writer, sheet_name='ç¸½è¦½', index=False)

            # ç‚ºæ¯å€‹æª”æ¡ˆå»ºç«‹å·¥ä½œè¡¨
            for filename, summary in self.codebook_data.items():
                # ç°¡åŒ–æª”åä½œç‚ºå·¥ä½œè¡¨åç¨±ï¼ˆExcelé™åˆ¶31å­—å…ƒï¼‰
                sheet_name = filename.replace('.csv', '')[:31]

                # å»ºç«‹æ¬„ä½è³‡è¨Šè¡¨
                fields_data = []
                for col_info in summary['æ¬„ä½è³‡è¨Š']:
                    row = {
                        'æ¬„ä½åç¨±': col_info['æ¬„ä½åç¨±'],
                        'ä¸­æ–‡èªªæ˜': col_info['ä¸­æ–‡èªªæ˜'],
                        'è³‡æ–™å‹æ…‹': col_info['è³‡æ–™å‹æ…‹'],
                        'ç¼ºå¤±å€¼æ•¸é‡': col_info['ç¼ºå¤±å€¼æ•¸é‡'],
                        'ç¼ºå¤±å€¼æ¯”ä¾‹': col_info['ç¼ºå¤±å€¼æ¯”ä¾‹'],
                        'å”¯ä¸€å€¼æ•¸é‡': col_info['å”¯ä¸€å€¼æ•¸é‡'],
                    }

                    # åŠ å…¥çµ±è¨ˆæ‘˜è¦
                    if 'çµ±è¨ˆæ‘˜è¦' in col_info and isinstance(col_info['çµ±è¨ˆæ‘˜è¦'], dict):
                        for key, value in col_info['çµ±è¨ˆæ‘˜è¦'].items():
                            if not isinstance(value, dict):
                                row[key] = value

                    fields_data.append(row)

                fields_df = pd.DataFrame(fields_data)
                fields_df.to_excel(writer, sheet_name=sheet_name, index=False)

        print(f"âœ… Excel Codebook å·²ç”Ÿæˆï¼š{output_path}")
        return str(output_path)

    def _generate_json(self) -> str:
        """ç”ŸæˆJSONæ ¼å¼çš„Codebook"""
        output_path = self.data_dir.parent / 'metadata' / 'data_dictionary.json'
        output_path.parent.mkdir(exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.codebook_data, f, ensure_ascii=False, indent=2)

        print(f"âœ… JSON Codebook å·²ç”Ÿæˆï¼š{output_path}")
        return str(output_path)


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == '__main__':
    # å»ºç«‹ç”Ÿæˆå™¨
    generator = CodebookGenerator(data_dir='data/raw')

    # ç”Ÿæˆæ‰€æœ‰æ ¼å¼çš„Codebook
    print("=" * 60)
    print("é–‹å§‹ç”Ÿæˆ Codebook...")
    print("=" * 60)

    markdown_path = generator.generate_codebook(output_format='markdown')
    excel_path = generator.generate_codebook(output_format='excel')
    json_path = generator.generate_codebook(output_format='json')

    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰ Codebook ç”Ÿæˆå®Œæˆï¼")
    print("=" * 60)
    print(f"\nğŸ“„ Markdown: {markdown_path}")
    print(f"ğŸ“Š Excel: {excel_path}")
    print(f"ğŸ“‹ JSON: {json_path}")