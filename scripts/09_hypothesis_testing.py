"""
09_hypothesis_testing.py
========================
ç¬¬å››ç« ï¼šçµ±è¨ˆæ¨è«– - å‡è¨­æª¢å®š

åŠŸèƒ½ï¼š
1. æ–‡åŒ–å·®ç•°å¡æ–¹æª¢å®š (H1)
2. å ´æ™¯ç‰¹å¾µå–®è®Šé‡åˆ†æ
3. äººå£çµ±è¨ˆè®Šæ•¸å–®è®Šé‡åˆ†æ

åŸ·è¡Œæ–¹å¼ï¼š
    python scripts/09_hypothesis_testing.py
"""

import sys
from pathlib import Path

# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„åŠ å…¥è·¯å¾‘
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from src.analysis.inference.chi_square import ChiSquareTest, run_chi_square_analysis
from src.analysis.inference.t_tests import UnivariateAnalysis, run_univariate_analysis
import pandas as pd
import numpy as np
import logging
from datetime import datetime


def setup_logging(log_dir: str = 'outputs/logs') -> logging.Logger:
    """è¨­å®šæ—¥èªŒ"""
    log_path = Path(log_dir)
    log_path.mkdir(parents=True, exist_ok=True)
    
    log_file = log_path / 'hypothesis_testing.log'
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, mode='w', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger(__name__)


def load_and_prepare_data(data_path: str = 'data/processed/featured_data.csv') -> pd.DataFrame:
    """
    è¼‰å…¥ä¸¦æº–å‚™åˆ†æè³‡æ–™
    
    Returns:
    --------
    DataFrame : éæ¿¾å¾Œçš„è³‡æ–™ (æ’é™¤Cluster==-1)
    """
    print("\n" + "="*60)
    print("è¼‰å…¥è³‡æ–™...")
    print("="*60)
    
    df = pd.read_csv(data_path)
    print(f"âœ… åŸå§‹è³‡æ–™: {len(df):,} è¡Œ")
    
    # éæ¿¾ Cluster == -1
    df_filtered = df[df['Cluster'] != -1].copy()
    removed = len(df) - len(df_filtered)
    print(f"âœ… éæ¿¾å¾Œè³‡æ–™: {len(df_filtered):,} è¡Œ")
    print(f"   (ç§»é™¤ {removed:,} è¡Œ Cluster==-1)")
    
    # æª¢æŸ¥è³‡æ–™
    print(f"\nè³‡æ–™æ¦‚è¦½:")
    print(f"  æ–‡åŒ–åœˆåˆ†ä½ˆ:")
    cluster_counts = df_filtered['Cluster'].value_counts().sort_index()
    cluster_names = {0: 'Western', 1: 'Eastern', 2: 'Southern'}
    for cluster, count in cluster_counts.items():
        name = cluster_names.get(cluster, str(cluster))
        print(f"    {name} (Cluster {cluster}): {count:,} ({count/len(df_filtered)*100:.1f}%)")
    
    print(f"\n  å ´æ™¯æ•¸: {df_filtered['ResponseID'].nunique():,}")
    print(f"  ä½¿ç”¨è€…æ•¸: {df_filtered['UserID'].nunique():,}")
    print(f"  åœ‹å®¶æ•¸: {df_filtered['UserCountry3'].nunique():,}")
    
    return df_filtered


def analyze_culture_differences(df: pd.DataFrame, 
                                output_dir: str = 'outputs/tables/chapter4',
                                figure_dir: str = 'outputs/figures/chapter4_inference') -> dict:
    """
    åˆ†ææ–‡åŒ–åœˆå·®ç•° (H1: æ–‡åŒ–åœˆå°é“å¾·é¸æ“‡æœ‰é¡¯è‘—å½±éŸ¿)
    
    Parameters:
    -----------
    df : DataFrame
        è³‡æ–™
    output_dir : str
        è¡¨æ ¼è¼¸å‡ºç›®éŒ„
    figure_dir : str
        åœ–è¡¨è¼¸å‡ºç›®éŒ„
        
    Returns:
    --------
    dict : åˆ†æçµæœ
    """
    print("\n" + "="*60)
    print("H1: æ–‡åŒ–åœˆå·®ç•°æª¢å®š")
    print("="*60)
    
    # åŸ·è¡Œå¡æ–¹åˆ†æ
    results = run_chi_square_analysis(
        data=df,
        outcome_var='chose_lawful',
        group_var='Cluster',
        alpha=0.05,
        save_dir=figure_dir
    )
    
    # å„²å­˜è©³ç´°çµæœ
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # 1. ä¸»è¦æª¢å®šçµæœ
    main_results_df = pd.DataFrame([{
        'æª¢å®š': 'å¡æ–¹æª¢å®š',
        'å‡è¨­': 'H1: æ–‡åŒ–åœˆå½±éŸ¿å®ˆæ³•é¸æ“‡',
        'Ï‡Â²çµ±è¨ˆé‡': results['main_results']['chi2'],
        'è‡ªç”±åº¦': results['main_results']['dof'],
        'på€¼': results['main_results']['p_value'],
        'CramÃ©r\'s V': results['main_results']['cramers_v'],
        'æ•ˆæœè§£é‡‹': results['main_results']['effect_interpretation'],
        'çµè«–': 'é¡¯è‘—' if results['main_results']['significant'] else 'ä¸é¡¯è‘—'
    }])
    
    main_results_df.to_csv(
        output_path / 'h1_chi_square_main_results.csv',
        index=False,
        encoding='utf-8-sig'
    )
    print(f"\nâœ… ä¸»è¦æª¢å®šçµæœ: {output_path / 'h1_chi_square_main_results.csv'}")
    
    # 2. äº‹å¾Œæ¯”è¼ƒ
    pairwise_df = results['pairwise_results']
    pairwise_df.to_csv(
        output_path / 'h1_pairwise_comparisons.csv',
        index=False,
        encoding='utf-8-sig'
    )
    print(f"âœ… äº‹å¾Œæ¯”è¼ƒçµæœ: {output_path / 'h1_pairwise_comparisons.csv'}")
    
    # 3. å„æ–‡åŒ–åœˆå®ˆæ³•é¸æ“‡ç‡
    proportions = results['main_results']['proportions']
    cluster_names = {0: 'Western', 1: 'Eastern', 2: 'Southern'}
    
    prop_df = pd.DataFrame([
        {
            'æ–‡åŒ–åœˆ': cluster_names.get(cluster, str(cluster)),
            'Cluster': cluster,
            'å®ˆæ³•é¸æ“‡ç‡': prop,
            'ç™¾åˆ†æ¯”': f"{prop*100:.1f}%"
        }
        for cluster, prop in proportions.items()
    ])
    
    prop_df.to_csv(
        output_path / 'h1_cluster_proportions.csv',
        index=False,
        encoding='utf-8-sig'
    )
    print(f"âœ… æ–‡åŒ–åœˆæ¯”ä¾‹: {output_path / 'h1_cluster_proportions.csv'}")
    
    return results


def analyze_scenario_features(df: pd.DataFrame,
                              output_dir: str = 'outputs/tables/chapter4',
                              figure_dir: str = 'outputs/figures/chapter4_inference') -> dict:
    """
    å ´æ™¯ç‰¹å¾µå–®è®Šé‡åˆ†æ
    
    Parameters:
    -----------
    df : DataFrame
        è³‡æ–™
    output_dir : str
        è¡¨æ ¼è¼¸å‡ºç›®éŒ„
    figure_dir : str
        åœ–è¡¨è¼¸å‡ºç›®éŒ„
        
    Returns:
    --------
    dict : åˆ†æçµæœ
    """
    print("\n" + "="*60)
    print("å ´æ™¯ç‰¹å¾µå–®è®Šé‡åˆ†æ")
    print("="*60)
    
    # å®šç¾©è¦åˆ†æçš„å ´æ™¯ç‰¹å¾µ
    scenario_vars = ['is_lawful', 'is_majority', 'lawful_vs_majority_conflict']
    
    # å®šç¾©è®Šæ•¸é¡å‹
    var_types = {
        'is_lawful': 'categorical',
        'is_majority': 'categorical',
        'lawful_vs_majority_conflict': 'categorical'
    }
    
    # åŸ·è¡Œæ‰¹æ¬¡åˆ†æ
    results = run_univariate_analysis(
        data=df,
        outcome_var='chose_lawful',
        test_vars=scenario_vars,
        var_types=var_types,
        alpha=0.05,
        save_dir=None  # ç¨å¾Œæ‰‹å‹•å„²å­˜
    )
    
    results_df = results['results_table']
    
    # å„²å­˜çµæœ
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    results_df.to_csv(
        output_path / 'scenario_features_univariate.csv',
        index=False,
        encoding='utf-8-sig'
    )
    print(f"\nâœ… å ´æ™¯ç‰¹å¾µåˆ†æ: {output_path / 'scenario_features_univariate.csv'}")
    
    # å„²å­˜åœ–è¡¨
    fig_path = Path(figure_dir)
    fig_path.mkdir(parents=True, exist_ok=True)
    
    results['figures']['forest_plot'].write_html(
        str(fig_path / 'scenario_features_forest_plot.html')
    )
    print(f"âœ… æ£®æ—åœ–: {fig_path / 'scenario_features_forest_plot.html'}")
    
    return results


def analyze_demographic_variables(df: pd.DataFrame,
                                  output_dir: str = 'outputs/tables/chapter4',
                                  figure_dir: str = 'outputs/figures/chapter4_inference') -> dict:
    """
    äººå£çµ±è¨ˆè®Šæ•¸å–®è®Šé‡åˆ†æ
    
    Parameters:
    -----------
    df : DataFrame
        è³‡æ–™
    output_dir : str
        è¡¨æ ¼è¼¸å‡ºç›®éŒ„
    figure_dir : str
        åœ–è¡¨è¼¸å‡ºç›®éŒ„
        
    Returns:
    --------
    dict : åˆ†æçµæœ
    """
    print("\n" + "="*60)
    print("äººå£çµ±è¨ˆè®Šæ•¸å–®è®Šé‡åˆ†æ")
    print("="*60)
    
    # å®šç¾©è¦åˆ†æçš„äººå£çµ±è¨ˆè®Šæ•¸
    demo_vars = ['Review_age', 'Review_political', 'Review_religious']
    
    # å®šç¾©è®Šæ•¸é¡å‹
    var_types = {
        'Review_age': 'continuous',
        'Review_political': 'continuous',
        'Review_religious': 'continuous'
    }
    
    # åŸ·è¡Œæ‰¹æ¬¡åˆ†æ
    results = run_univariate_analysis(
        data=df,
        outcome_var='chose_lawful',
        test_vars=demo_vars,
        var_types=var_types,
        alpha=0.05,
        save_dir=None
    )
    
    results_df = results['results_table']
    
    # å„²å­˜çµæœ
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    results_df.to_csv(
        output_path / 'demographic_univariate.csv',
        index=False,
        encoding='utf-8-sig'
    )
    print(f"\nâœ… äººå£çµ±è¨ˆåˆ†æ: {output_path / 'demographic_univariate.csv'}")
    
    # å„²å­˜åœ–è¡¨
    fig_path = Path(figure_dir)
    fig_path.mkdir(parents=True, exist_ok=True)
    
    results['figures']['forest_plot'].write_html(
        str(fig_path / 'demographic_forest_plot.html')
    )
    print(f"âœ… æ£®æ—åœ–: {fig_path / 'demographic_forest_plot.html'}")
    
    return results


def generate_summary_report(culture_results: dict,
                            scenario_results: dict,
                            demo_results: dict,
                            output_dir: str = 'report/drafts') -> None:
    """
    ç”Ÿæˆæ‘˜è¦å ±å‘Š (Markdownæ ¼å¼)
    
    Parameters:
    -----------
    culture_results : dict
        æ–‡åŒ–å·®ç•°åˆ†æçµæœ
    scenario_results : dict
        å ´æ™¯ç‰¹å¾µåˆ†æçµæœ
    demo_results : dict
        äººå£çµ±è¨ˆåˆ†æçµæœ
    output_dir : str
        å ±å‘Šè¼¸å‡ºç›®éŒ„
    """
    print("\n" + "="*60)
    print("ç”Ÿæˆæ‘˜è¦å ±å‘Š")
    print("="*60)
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    report_file = output_path / 'chapter4_section1_hypothesis_testing.md'
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# ç¬¬4ç«  çµ±è¨ˆæ¨è«–\n\n")
        f.write("## 4.1 å‡è¨­æª¢å®š\n\n")
        
        # H1: æ–‡åŒ–åœˆå·®ç•°
        f.write("### H1: æ–‡åŒ–åœˆå°é“å¾·é¸æ“‡çš„å½±éŸ¿\n\n")
        f.write("**ç ”ç©¶å‡è¨­**: ä¸åŒæ–‡åŒ–åœˆï¼ˆWestern, Eastern, Southernï¼‰åœ¨ã€Œå®ˆæ³•vs.æ•ˆç›Šã€é“å¾·å…©é›£ä¸­çš„é¸æ“‡å­˜åœ¨é¡¯è‘—å·®ç•°ã€‚\n\n")
        
        main = culture_results['main_results']
        
        f.write("**æª¢å®šæ–¹æ³•**: å¡æ–¹æª¢å®š (Chi-Square Test)\n\n")
        f.write("**çµæœ**:\n\n")
        p_str = "< .001" if main['p_value'] < 0.001 else f"= {main['p_value']:.3f}"
        f.write(f"- Ï‡Â²({main['dof']}) = {main['chi2']:.3f}, p {p_str}\n")
        f.write(f"- CramÃ©r's V = {main['cramers_v']:.3f} ({main['effect_interpretation']})\n\n")
        
        if main['significant']:
            f.write("**çµè«–**: âœ… æ–‡åŒ–åœˆé–“å­˜åœ¨é¡¯è‘—å·®ç•° (p < 0.05)\n\n")
        else:
            f.write("**çµè«–**: âŒ æ–‡åŒ–åœˆé–“ç„¡é¡¯è‘—å·®ç•° (p â‰¥ 0.05)\n\n")
        
        f.write("**å„æ–‡åŒ–åœˆå®ˆæ³•é¸æ“‡ç‡**:\n\n")
        cluster_names = {0: 'Western', 1: 'Eastern', 2: 'Southern'}
        for cluster, prop in main['proportions'].items():
            name = cluster_names.get(cluster, str(cluster))
            f.write(f"- {name}: {prop*100:.1f}%\n")
        
        f.write("\n**äº‹å¾Œæ¯”è¼ƒ** (Bonferroniæ ¡æ­£):\n\n")
        pairwise = culture_results['pairwise_results']
        
        f.write("| æ¯”è¼ƒ | æ¯”ä¾‹å·®ç•° | på€¼(æ ¡æ­£å¾Œ) | é¡¯è‘— |\n")
        f.write("|------|----------|------------|------|\n")
        
        for _, row in pairwise.iterrows():
            g1_name = cluster_names.get(row['Group1'], str(row['Group1']))
            g2_name = cluster_names.get(row['Group2'], str(row['Group2']))
            sig = 'âœ“' if row['significant'] else ''
            
            f.write(f"| {g1_name} vs {g2_name} | {row['Diff']:+.3f} | {row['p_adjusted']:.4f} | {sig} |\n")
        
        f.write("\n---\n\n")
        
        # å ´æ™¯ç‰¹å¾µåˆ†æ
        f.write("### å ´æ™¯ç‰¹å¾µå–®è®Šé‡åˆ†æ\n\n")
        f.write("æª¢é©—å ´æ™¯æœ¬èº«çš„ç‰¹å¾µï¼ˆå®ˆæ³•æ€§ã€å¤šæ•¸æ€§ã€è¡çªæ€§ï¼‰æ˜¯å¦å½±éŸ¿å®ˆæ³•é¸æ“‡ã€‚\n\n")
        
        scenario_table = scenario_results['results_table']
        
        f.write("| è®Šæ•¸ | æª¢å®šæ–¹æ³• | çµ±è¨ˆé‡ | på€¼ | æ•ˆæœé‡ | é¡¯è‘— |\n")
        f.write("|------|---------|--------|-----|--------|------|\n")
        
        for _, row in scenario_table.iterrows():
            f.write(f"| {row['è®Šæ•¸']} | {row['æª¢å®šæ–¹æ³•']} | {row['çµ±è¨ˆé‡']} | {row['på€¼']:.4f} | {row['æ•ˆæœé‡']:.3f} | {row['é¡¯è‘—']} |\n")
        
        f.write("\n---\n\n")
        
        # äººå£çµ±è¨ˆè®Šæ•¸åˆ†æ
        f.write("### äººå£çµ±è¨ˆè®Šæ•¸å–®è®Šé‡åˆ†æ\n\n")
        f.write("æª¢é©—å€‹äººç‰¹å¾µï¼ˆå¹´é½¡ã€æ”¿æ²»å‚¾å‘ã€å®—æ•™ä¿¡ä»°ï¼‰æ˜¯å¦å½±éŸ¿å®ˆæ³•é¸æ“‡ã€‚\n\n")
        
        demo_table = demo_results['results_table']
        
        f.write("| è®Šæ•¸ | æª¢å®šæ–¹æ³• | çµ±è¨ˆé‡ | på€¼ | æ•ˆæœé‡ | æ•ˆæœè§£é‡‹ | é¡¯è‘— |\n")
        f.write("|------|---------|--------|-----|--------|---------|------|\n")
        
        for _, row in demo_table.iterrows():
            f.write(f"| {row['è®Šæ•¸']} | {row['æª¢å®šæ–¹æ³•']} | {row['çµ±è¨ˆé‡']} | {row['på€¼']:.4f} | {row['æ•ˆæœé‡']:.3f} | {row['æ•ˆæœè§£é‡‹']} | {row['é¡¯è‘—']} |\n")
        
        f.write("\n---\n\n")
        
        # é—œéµç™¼ç¾æ‘˜è¦
        f.write("### é—œéµç™¼ç¾æ‘˜è¦\n\n")
        
        # çµ±è¨ˆé¡¯è‘—è®Šæ•¸
        total_tests = len(scenario_table) + len(demo_table) + 1  # +1 for chi-square
        sig_tests = (
            (1 if main['significant'] else 0) +
            (scenario_table['é¡¯è‘—'] == 'âœ“').sum() +
            (demo_table['é¡¯è‘—'] == 'âœ“').sum()
        )
        
        f.write(f"1. **æ•´é«”æª¢å®š**: {sig_tests}/{total_tests} é …æª¢å®šé”åˆ°çµ±è¨ˆé¡¯è‘— (Î±=0.05)\n\n")
        
        if main['significant']:
            f.write(f"2. **æ–‡åŒ–å·®ç•°**: ä¸‰å¤§æ–‡åŒ–åœˆçš„å®ˆæ³•é¸æ“‡ç‡å­˜åœ¨é¡¯è‘—å·®ç•°\n")
            # æ‰¾å‡ºæœ€é«˜å’Œæœ€ä½
            max_cluster = max(main['proportions'].items(), key=lambda x: x[1])
            min_cluster = min(main['proportions'].items(), key=lambda x: x[1])
            
            max_name = cluster_names.get(max_cluster[0], str(max_cluster[0]))
            min_name = cluster_names.get(min_cluster[0], str(min_cluster[0]))
            
            f.write(f"   - {max_name}æœ€é«˜ ({max_cluster[1]*100:.1f}%)\n")
            f.write(f"   - {min_name}æœ€ä½ ({min_cluster[1]*100:.1f}%)\n\n")
        
        f.write("3. **æ•ˆæœé‡**: æ‰€æœ‰æª¢å®šçš„æ•ˆæœé‡å‡ç‚ºå°åˆ°ä¸­ç­‰ï¼Œç¬¦åˆé“å¾·åˆ¤æ–·çš„è¤‡é›œæ€§\n\n")
        
        f.write("4. **å¯¦å‹™æ„ç¾©**: é›–ç„¶çµ±è¨ˆé¡¯è‘—ï¼Œä½†æ•ˆæœé‡æé†’æˆ‘å€‘é¿å…éåº¦è§£è®€æ–‡åŒ–å·®ç•°çš„å¯¦è³ªå½±éŸ¿\n\n")
    
    print(f"âœ… æ‘˜è¦å ±å‘Š: {report_file}")


def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    print("\n" + "=" * 70)
    print("ğŸ” MIT Moral Machine - å‡è¨­æª¢å®šåˆ†æ (Chapter 4.1)")
    print("=" * 70)
    
    # è¨­å®šæ—¥èªŒ
    logger = setup_logging()
    logger.info("é–‹å§‹åŸ·è¡Œå‡è¨­æª¢å®šåˆ†æ...")
    
    try:
        # Step 1: è¼‰å…¥è³‡æ–™
        df = load_and_prepare_data()
        
        # Step 2: H1 - æ–‡åŒ–åœˆå·®ç•°æª¢å®š
        culture_results = analyze_culture_differences(df)
        
        # Step 3: å ´æ™¯ç‰¹å¾µåˆ†æ
        scenario_results = analyze_scenario_features(df)
        
        # Step 4: äººå£çµ±è¨ˆè®Šæ•¸åˆ†æ
        demo_results = analyze_demographic_variables(df)
        
        # Step 5: ç”Ÿæˆæ‘˜è¦å ±å‘Š
        generate_summary_report(culture_results, scenario_results, demo_results)
        
        # å®Œæˆ
        print("\n" + "=" * 70)
        print("âœ… å‡è¨­æª¢å®šåˆ†æå®Œæˆï¼")
        print("=" * 70)
        print("\nğŸ“Š å·²ç”¢ç”Ÿä»¥ä¸‹è¼¸å‡º:")
        print("  ã€è¡¨æ ¼ã€‘")
        print("  - outputs/tables/chapter4/h1_chi_square_main_results.csv")
        print("  - outputs/tables/chapter4/h1_pairwise_comparisons.csv")
        print("  - outputs/tables/chapter4/h1_cluster_proportions.csv")
        print("  - outputs/tables/chapter4/scenario_features_univariate.csv")
        print("  - outputs/tables/chapter4/demographic_univariate.csv")
        print("\n  ã€åœ–è¡¨ã€‘")
        print("  - outputs/figures/chapter4_inference/contingency_heatmap.html")
        print("  - outputs/figures/chapter4_inference/proportion_bar_chart.html")
        print("  - outputs/figures/chapter4_inference/pairwise_comparison.html")
        print("  - outputs/figures/chapter4_inference/scenario_features_forest_plot.html")
        print("  - outputs/figures/chapter4_inference/demographic_forest_plot.html")
        print("\n  ã€å ±å‘Šã€‘")
        print("  - report/drafts/chapter4_section1_hypothesis_testing.md")
        print("  - outputs/logs/hypothesis_testing.log")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥: python scripts/10_logistic_regression.py")
        print("=" * 70 + "\n")
        
        logger.info("å‡è¨­æª¢å®šåˆ†æå®Œæˆ")
        
    except Exception as e:
        logger.error(f"åŸ·è¡Œå¤±æ•—: {e}", exc_info=True)
        print(f"\nâŒ éŒ¯èª¤: {e}")
        raise


if __name__ == '__main__':
    main()