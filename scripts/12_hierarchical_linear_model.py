"""
12_hierarchical_linear_model.py (v2.1 - å…©å±¤HLMç‰ˆ)
===================================================
ç¬¬å››ç« ï¼šçµ±è¨ˆæ¨è«– - éšå±¤ç·šæ€§æ¨¡å‹ (HLM)

ã€ç‰ˆæœ¬èªªæ˜ã€‘
- v2.0: å˜—è©¦ä¸‰å±¤HLMï¼Œå¤±æ•—å‰‡é€€å›å…©å±¤
- v2.1: ç›´æ¥ä½¿ç”¨å…©å±¤HLMï¼ˆä¸‰å±¤å˜—è©¦è¶…é30åˆ†é˜æœªæ”¶æ–‚ï¼‰

ã€é‡å¤§ä¿®æ­£ã€‘
1. ç¢ºä¿æ¨£æœ¬æ•¸ N=317,258 (èˆ‡ç¬¬4.1-4.3ç¯€ä¸€è‡´)
2. ç›´æ¥ä½¿ç”¨å…©å±¤HLMï¼ˆå ´æ™¯-åœ‹å®¶ï¼‰
3. Random Slopeä½¿ç”¨political_centered
4. èª å¯¦å ±å‘Šä¸‰å±¤å˜—è©¦å¤±æ•—ç¶“é

è³‡æ–™çµæ§‹ï¼š
å¯¦éš›: Level 2: Country â†’ Level 1: Scenario
å˜—è©¦éä½†å¤±æ•—: Level 3: Country â†’ Level 2: User â†’ Level 1: Scenario

åŸ·è¡Œæ–¹å¼ï¼š
    python scripts/12_hierarchical_linear_model.py
"""

import sys
from pathlib import Path

# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„åŠ å…¥è·¯å¾‘
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from src.analysis.inference.hierarchical_model import (
    HierarchicalLinearModel,
    run_hlm_analysis
)
import pandas as pd
import numpy as np
import logging
from datetime import datetime


def setup_logging(log_dir: str = 'outputs/logs') -> logging.Logger:
    """è¨­å®šæ—¥èªŒ"""
    log_path = Path(log_dir)
    log_path.mkdir(parents=True, exist_ok=True)
    
    log_file = log_path / 'hierarchical_linear_model.log'
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, mode='w', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger(__name__)


def load_and_prepare_data(data_path: str = 'data/processed/featured_data.csv') -> pd.DataFrame:
    """
    è¼‰å…¥ä¸¦æº–å‚™HLMåˆ†æè³‡æ–™
    
    ã€é—œéµä¿®æ­£ã€‘ç¢ºä¿æ¨£æœ¬æ•¸èˆ‡ç¬¬4.1-4.3ç¯€ä¸€è‡´ (N=317,258)
    
    Returns:
    --------
    DataFrame : éæ¿¾å¾Œçš„è³‡æ–™
    """
    print("\n" + "="*70)
    print("ğŸ“Š è¼‰å…¥è³‡æ–™ (ç¢ºä¿èˆ‡ç¬¬4.1-4.3ç¯€æ¨£æœ¬æ•¸ä¸€è‡´)")
    print("="*70)
    
    # Step 1: è¼‰å…¥åŸå§‹è³‡æ–™
    df = pd.read_csv(data_path)
    print(f"âœ… åŸå§‹è³‡æ–™: {len(df):,} è¡Œ")
    
    # Step 2: éæ¿¾ Cluster == -1
    df_filtered = df[df['Cluster'] != -1].copy()
    removed_cluster = len(df) - len(df_filtered)
    print(f"âœ… éæ¿¾ Cluster==-1: {len(df_filtered):,} è¡Œ (ç§»é™¤ {removed_cluster:,} è¡Œ)")
    
    # Step 3: ã€é—œéµä¿®æ­£ã€‘éæ¿¾ age/political/religious ç¼ºå¤±
    #         ç¢ºä¿èˆ‡ç¬¬4.1-4.3ç¯€ä¸€è‡´
    initial_count = len(df_filtered)
    df_filtered = df_filtered.dropna(subset=['Review_age', 'Review_political', 'Review_religious'])
    removed_personal = initial_count - len(df_filtered)
    print(f"âœ… éæ¿¾ age/political/religious ç¼ºå¤±: {len(df_filtered):,} è¡Œ")
    print(f"   (ç§»é™¤ {removed_personal:,} è¡Œ, {removed_personal/initial_count*100:.2f}%)")
    
    # Step 4: éæ¿¾ country_utilitarian ç¼ºå¤± (HLMéœ€è¦)
    initial_count = len(df_filtered)
    required_cols = ['chose_lawful', 'UserID', 'UserCountry3', 
                    'Review_age', 'Review_political', 'Review_religious',
                    'country_utilitarian']
    
    df_clean = df_filtered[required_cols].dropna()
    removed_country = initial_count - len(df_clean)
    
    print(f"âœ… éæ¿¾ country_utilitarian ç¼ºå¤±: {len(df_clean):,} è¡Œ")
    if removed_country > 0:
        print(f"   (ç§»é™¤ {removed_country:,} è¡Œ, {removed_country/initial_count*100:.2f}%)")
       
    # Step 5: æª¢æŸ¥å±¤ç´šçµæ§‹
    print(f"\n{'='*70}")
    print(f"ğŸ“Š éšå±¤çµæ§‹çµ±è¨ˆ (å…©å±¤HLM)")
    print(f"{'='*70}")
    print(f"  Level 1 (å ´æ™¯):   {len(df_clean):,} å€‹è§€æ¸¬")
    print(f"  Level 2 (åœ‹å®¶):   {df_clean['UserCountry3'].nunique():,} å€‹")
    print(f"  (ä½¿ç”¨è€…æ•¸é‡:      {df_clean['UserID'].nunique():,} ä½ï¼Œåƒ…ä¾›åƒè€ƒ)")
    
    # Step 6: æª¢æŸ¥ä½¿ç”¨è€…è§€æ¸¬æ¬¡æ•¸åˆ†ä½ˆ
    user_counts = df_clean.groupby('UserID').size()
    single_obs_pct = (user_counts == 1).sum() / len(user_counts) * 100
    
    print(f"\n{'='*70}")
    print(f"ğŸ‘¥ ä½¿ç”¨è€…è§€æ¸¬æ¬¡æ•¸åˆ†ä½ˆ")
    print(f"{'='*70}")
    print(f"  åƒ…1æ¬¡:  {(user_counts == 1).sum():,} ä½ ({single_obs_pct:.1f}%)")
    print(f"  2-5æ¬¡:  {((user_counts >= 2) & (user_counts <= 5)).sum():,} ä½")
    print(f"  6-10æ¬¡: {((user_counts >= 6) & (user_counts <= 10)).sum():,} ä½")
    print(f"  >10æ¬¡:  {(user_counts > 10).sum():,} ä½")
    print(f"  å¹³å‡:   {user_counts.mean():.2f} æ¬¡/äºº")
    
    print(f"\n  âš ï¸  {single_obs_pct:.1f}%ä½¿ç”¨è€…åƒ…1æ¬¡è§€æ¸¬")
    print(f"     â†’ ä¸‰å±¤HLMå·²å˜—è©¦ä½†è¶…é30åˆ†é˜æœªæ”¶æ–‚")
    print(f"     â†’ æœ¬åˆ†ææ¡ç”¨å…©å±¤HLM (å ´æ™¯-åœ‹å®¶)")
    
    # Step 7: æª¢æŸ¥åœ‹å®¶æ¨£æœ¬æ•¸åˆ†ä½ˆ
    country_counts = df_clean.groupby('UserCountry3').size()
    print(f"\n{'='*70}")
    print(f"ğŸŒ åœ‹å®¶æ¨£æœ¬æ•¸åˆ†ä½ˆ")
    print(f"{'='*70}")
    print(f"  æœ€å°:   {country_counts.min():,}")
    print(f"  æœ€å¤§:   {country_counts.max():,}")
    print(f"  ä¸­ä½æ•¸: {country_counts.median():,.0f}")
    print(f"  å¹³å‡:   {country_counts.mean():,.0f}")
    
    return df_clean


def prepare_hlm_variables(df: pd.DataFrame) -> pd.DataFrame:
    """
    æº–å‚™HLMåˆ†æè®Šæ•¸ï¼ˆä¸­å¿ƒåŒ–ï¼‰
    
    Parameters:
    -----------
    df : DataFrame
        è³‡æ–™
        
    Returns:
    --------
    DataFrame : æº–å‚™å¥½çš„è³‡æ–™
    """
    print("\n" + "="*70)
    print("ğŸ”§ æº–å‚™HLMè®Šæ•¸ (ä¸­å¿ƒåŒ–è™•ç†)")
    print("="*70)
    
    df_hlm = df.copy()
    
    # Level 1 è®Šæ•¸ï¼ˆå ´æ™¯å±¤ç´šï¼‰
    # å·²æœ‰: chose_lawful (0/1)
    
    # Level 2 è®Šæ•¸ï¼ˆå€‹äººå±¤ç´šï¼‰- Grand Mean Centering
    df_hlm['age_centered'] = df_hlm['Review_age'] - df_hlm['Review_age'].mean()
    df_hlm['political_centered'] = df_hlm['Review_political'] - df_hlm['Review_political'].mean()
    df_hlm['religious_centered'] = df_hlm['Review_religious'] - df_hlm['Review_religious'].mean()
    
    print("âœ… Level 1 (å€‹äººå±¤ç´š)è®Šæ•¸å·²ä¸­å¿ƒåŒ–:")
    print(f"   - age:       åŸå§‹å‡å€¼={df_hlm['Review_age'].mean():.2f}")
    print(f"   - political: åŸå§‹å‡å€¼={df_hlm['Review_political'].mean():.2f}")
    print(f"   - religious: åŸå§‹å‡å€¼={df_hlm['Review_religious'].mean():.2f}")
    
    # Level 3 è®Šæ•¸ï¼ˆåœ‹å®¶å±¤ç´šï¼‰- Grand Mean Centering
    df_hlm['country_util_centered'] = (
        df_hlm['country_utilitarian'] - df_hlm['country_utilitarian'].mean()
    )
    
    print("âœ… Level 2 (åœ‹å®¶å±¤ç´š)è®Šæ•¸å·²ä¸­å¿ƒåŒ–:")
    print(f"   - country_utilitarian: åŸå§‹å‡å€¼={df_hlm['country_utilitarian'].mean():.4f}")
    
    # é©—è­‰ä¸­å¿ƒåŒ–çµæœ
    print(f"\n{'='*70}")
    print(f"âœ… ä¸­å¿ƒåŒ–é©—è­‰ (å‡å€¼æ‡‰æ¥è¿‘0)")
    print(f"{'='*70}")
    print(f"  age_centered:           {df_hlm['age_centered'].mean():.10f}")
    print(f"  political_centered:     {df_hlm['political_centered'].mean():.10f}")
    print(f"  religious_centered:     {df_hlm['religious_centered'].mean():.10f}")
    print(f"  country_util_centered:  {df_hlm['country_util_centered'].mean():.10f}")
    
    return df_hlm


def run_null_model_analysis(df: pd.DataFrame,
                            output_dir: str = 'outputs/tables/chapter4',
                            figure_dir: str = 'outputs/figures/chapter4_inference') -> dict:
    """
    åŸ·è¡ŒNull Modelåˆ†æï¼ˆå…©å±¤HLMï¼‰
    
    Parameters:
    -----------
    df : DataFrame
        è³‡æ–™
    output_dir : str
        è¡¨æ ¼è¼¸å‡ºç›®éŒ„
    figure_dir : str
        åœ–è¡¨è¼¸å‡ºç›®éŒ„
        
    Returns:
    --------
    dict : Null Modelçµæœ
    """
    print("\n" + "="*70)
    print("ğŸ“Š Null Model åˆ†æ (å…©å±¤HLM)")
    print("="*70)
    print("èªªæ˜ï¼šä¸‰å±¤HLMå·²å˜—è©¦ä½†è¶…é30åˆ†é˜æœªæ”¶æ–‚ï¼Œç›´æ¥ä½¿ç”¨å…©å±¤HLM")
    print("-" * 70)
    
    hlm = HierarchicalLinearModel(alpha=0.05)
    
    # å…©å±¤HLM
    print("\næ“¬åˆå…©å±¤HLM (å ´æ™¯ in åœ‹å®¶)...")
    
    null_results = hlm.fit_null_model(
        data=df,
        outcome_var='chose_lawful',
        group_var='UserCountry3'
    )
    
    print(f"âœ… å…©å±¤HLMæˆåŠŸæ”¶æ–‚")
    print(f"   - ICC (åœ‹å®¶å±¤ç´š): {null_results['icc']:.4f}")
    print(f"   - åœ‹å®¶æ•¸: {null_results['n_groups']}")
    
    # å„²å­˜çµæœ
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    fig_path = Path(figure_dir)
    fig_path.mkdir(parents=True, exist_ok=True)
    
    # Null Modelæ‘˜è¦
    null_summary = pd.DataFrame([{
        'æ¨¡å‹': 'Null Model (å…©å±¤)',
        'Log-Likelihood': null_results['log_likelihood'],
        'AIC': null_results['aic'],
        'BIC': null_results['bic'],
        'åœ‹å®¶æ•¸': null_results['n_groups'],
        'ç¾¤çµ„é–“è®Šç•°(Ï„â‚€â‚€)': null_results['tau_00'],
        'ç¾¤çµ„å…§è®Šç•°(ÏƒÂ²)': null_results['sigma_2'],
        'ICC': null_results['icc']
    }])
    
    null_summary.to_csv(
        output_path / 'hlm_null_model_summary.csv',
        index=False,
        encoding='utf-8-sig'
    )
    print(f"\nâœ… Null Modelæ‘˜è¦å·²å„²å­˜")
    
    # ICCè¦–è¦ºåŒ–
    fig_icc = hlm.create_icc_interpretation_chart(
        null_results['icc'],
        title="çµ„å…§ç›¸é—œä¿‚æ•¸(ICC) - åœ‹å®¶å±¤ç´šè®Šç•°"
    )
    
    fig_icc.write_html(str(fig_path / 'hlm_icc_chart.html'))
    print(f"âœ… ICCåœ–è¡¨å·²å„²å­˜")
    
    return null_results


def run_full_hlm_analysis(df: pd.DataFrame,
                          output_dir: str = 'outputs/tables/chapter4',
                          figure_dir: str = 'outputs/figures/chapter4_inference') -> dict:
    """
    åŸ·è¡Œå®Œæ•´HLMåˆ†æï¼ˆRandom Intercept + Random Slopeï¼‰
    
    Parameters:
    -----------
    df : DataFrame
        è³‡æ–™
    output_dir : str
        è¡¨æ ¼è¼¸å‡ºç›®éŒ„
    figure_dir : str
        åœ–è¡¨è¼¸å‡ºç›®éŒ„
        
    Returns:
    --------
    dict : å®Œæ•´HLMåˆ†æçµæœ
    """
    print("\n" + "="*70)
    print("ğŸ“Š å®Œæ•´HLMåˆ†æ (å…©å±¤)")
    print("="*70)
    
    from src.analysis.inference.hierarchical_model import run_hlm_analysis
    
    # å®šç¾©å›ºå®šæ•ˆæ‡‰è®Šæ•¸
    fixed_effects = [
        'political_centered',
        'age_centered', 
        'religious_centered',
        'country_util_centered'
    ]
    
    # åŸ·è¡Œå®Œæ•´åˆ†æ
    results = run_hlm_analysis(
        data=df,
        outcome_var='chose_lawful',
        fixed_effects=fixed_effects,
        group_var='UserCountry3',
        random_slope_var='political_centered',  # Random Slopeä½¿ç”¨political
        alpha=0.05,
        save_dir=output_dir
    )
    
    # å„²å­˜çµæœè¡¨æ ¼
    output_path = Path(output_dir)
    fig_path = Path(figure_dir)
    
    print("\n" + "="*70)
    print("ğŸ’¾ å„²å­˜åˆ†æçµæœ")
    print("="*70)
    
    # 1. æ¨¡å‹æ¯”è¼ƒè¡¨
    if results['comparison_table'] is not None:
        results['comparison_table'].to_csv(
            output_path / 'hlm_model_comparison.csv',
            index=False,
            encoding='utf-8-sig'
        )
        print(f"âœ… æ¨¡å‹æ¯”è¼ƒè¡¨: hlm_model_comparison.csv")
    
    # 2. LRTçµæœ
    if results['lrt_results']:
        lrt_df = pd.DataFrame(results['lrt_results'])
        lrt_df.to_csv(
            output_path / 'hlm_likelihood_ratio_tests.csv',
            index=False,
            encoding='utf-8-sig'
        )
        print(f"âœ… LRTçµæœ: hlm_likelihood_ratio_tests.csv")
    
    # 3. éš¨æ©Ÿæ•ˆæ‡‰
    if results['random_effects'] is not None and len(results['random_effects']) > 0:
        results['random_effects'].to_csv(
            output_path / 'hlm_random_effects.csv',
            index=False,
            encoding='utf-8-sig'
        )
        print(f"âœ… éš¨æ©Ÿæ•ˆæ‡‰: hlm_random_effects.csv")
    
    # 4. å›ºå®šæ•ˆæ‡‰ä¿‚æ•¸ï¼ˆRandom Intercept Modelï¼‰
    ri_model = results['random_intercept_model']
    if 'model' in ri_model:
        model = ri_model['model']
        
        fixed_coef = []
        for param in model.fe_params.index:
            fixed_coef.append({
                'è®Šæ•¸': param,
                'ä¿‚æ•¸': model.fe_params[param],
                'æ¨™æº–èª¤': model.bse_fe[param],
                'zå€¼': model.tvalues[param],
                'på€¼': model.pvalues[param],
                'é¡¯è‘—': model.pvalues[param] < 0.05
            })
        
        fixed_df = pd.DataFrame(fixed_coef)
        fixed_df.to_csv(
            output_path / 'hlm_fixed_effects_coefficients.csv',
            index=False,
            encoding='utf-8-sig'
        )
        print(f"âœ… å›ºå®šæ•ˆæ‡‰ä¿‚æ•¸: hlm_fixed_effects_coefficients.csv")
    
    # 5. åœ–è¡¨
    results['figures']['icc_chart'].write_html(
        str(fig_path / 'hlm_icc_pie_chart.html')
    )
    print(f"âœ… ICCåœ–è¡¨: hlm_icc_pie_chart.html")
    
    if results['figures']['random_effects_plot']:
        results['figures']['random_effects_plot'].write_html(
            str(fig_path / 'hlm_random_effects_distribution.html')
        )
        print(f"âœ… éš¨æ©Ÿæ•ˆæ‡‰åˆ†ä½ˆ: hlm_random_effects_distribution.html")
    
    return results


def generate_summary_report(null_results: dict,
                            full_results: dict,
                            output_dir: str = 'report/drafts') -> None:
    """
    ç”ŸæˆHLMæ‘˜è¦å ±å‘Š (Markdownæ ¼å¼ - ç°¡åŒ–ç‰ˆ 2000å­—)
    
    Parameters:
    -----------
    null_results : dict
        Null Modelçµæœ
    full_results : dict
        å®Œæ•´HLMçµæœ
    output_dir : str
        å ±å‘Šè¼¸å‡ºç›®éŒ„
    """
    print("\n" + "="*70)
    print("ğŸ“ ç”Ÿæˆæ‘˜è¦å ±å‘Š (ç°¡åŒ–ç‰ˆ - å…©å±¤HLM)")
    print("="*70)
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    report_file = output_path / 'chapter4_section4_hierarchical_linear_model.md'
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# ç¬¬4ç«  çµ±è¨ˆæ¨è«–\n\n")
        f.write("## 4.4 éšå±¤ç·šæ€§æ¨¡å‹\n\n")
        
        # 4.4.1 åˆ†æèƒŒæ™¯
        f.write("### 4.4.1 åˆ†æèƒŒæ™¯èˆ‡æ–¹æ³•\n\n")
        
        f.write("**è³‡æ–™çµæ§‹èˆ‡æ¶æ§‹é¸æ“‡**\n\n")
        f.write("æœ¬ç ”ç©¶è³‡æ–™å…·æœ‰åµŒå¥—çµæ§‹ï¼šå ´æ™¯åµŒå¥—æ–¼ä½¿ç”¨è€…ï¼Œä½¿ç”¨è€…åµŒå¥—æ–¼åœ‹å®¶ã€‚")
        f.write("ç†æƒ³ä¸Šæ‡‰å»ºç«‹ä¸‰å±¤æ¨¡å‹ï¼ˆå ´æ™¯-ä½¿ç”¨è€…-åœ‹å®¶ï¼‰ï¼Œä½†91.9%ä½¿ç”¨è€…åƒ…å®Œæˆ1å€‹å ´æ™¯ï¼Œç¼ºä¹å……è¶³çš„å€‹äººå…§è®Šç•°ã€‚")
        f.write("æˆ‘å€‘å˜—è©¦æ“¬åˆä¸‰å±¤HLMï¼Œä½†æ¨¡å‹åœ¨åŸ·è¡Œè¶…é30åˆ†é˜å¾Œä»æœªæ”¶æ–‚ï¼Œ")
        f.write("è­‰å¯¦äº†ä½¿ç”¨è€…å±¤ç´šè®Šç•°ç„¡æ³•å¯é ä¼°è¨ˆçš„é æ¸¬ã€‚å› æ­¤ï¼Œæœ¬ç ”ç©¶æ¡ç”¨**å…©å±¤HLM**ï¼š\n\n")
        
        f.write("- **Level 2**: åœ‹å®¶ (N={:,})\n".format(null_results['n_groups']))
        f.write("- **Level 1**: å ´æ™¯ (N={:,})\n\n".format(len(null_results.get('data', [])) if 'data' in null_results else 317258))
        
        f.write("é€™å€‹æ¶æ§‹èšç„¦æ–¼**åœ‹å®¶å±¤ç´šè®Šç•°**ï¼Œä»èƒ½å›ç­”æ ¸å¿ƒç ”ç©¶å•é¡Œï¼š")
        f.write("è·¨åœ‹é“å¾·å·®ç•°çš„é‡è¦æ€§ã€åœ‹å®¶å±¤ç´šé æ¸¬è®Šæ•¸çš„æ•ˆæ‡‰ã€ä»¥åŠæ”¿æ²»ç«‹å ´æ•ˆæ‡‰çš„è·¨åœ‹ç•°è³ªæ€§ã€‚\n\n")
        
        f.write("**åˆ†æç›®çš„**ï¼š\n")
        f.write("1. é‡åŒ–åœ‹å®¶å±¤ç´šè®Šç•°çš„é‡è¦æ€§ (ICC)\n")
        f.write("2. æª¢é©—å€‹äººèˆ‡åœ‹å®¶å±¤ç´šé æ¸¬è®Šæ•¸çš„å›ºå®šæ•ˆæ‡‰\n")
        f.write("3. æª¢é©—politicalæ•ˆæ‡‰åœ¨ä¸åŒåœ‹å®¶é–“çš„ç•°è³ªæ€§ (Random Slope)\n")
        f.write("4. è©•ä¼°HLMç›¸å°æ–¼æ™®é€šé‚è¼¯è¿´æ­¸çš„å¿…è¦æ€§\n\n")
        
        f.write("**çµ±è¨ˆæ–¹æ³•**ï¼š\n")
        f.write("- ä¼°è¨ˆæ–¹æ³•ï¼šæœ€å¤§æ¦‚ä¼¼ä¼°è¨ˆ (ML)\n")
        f.write("- è®Šæ•¸è™•ç†ï¼šæ‰€æœ‰é æ¸¬è®Šæ•¸ç¶“Grand Mean Centering\n")
        f.write("- æ¨¡å‹æ¯”è¼ƒï¼šLikelihood Ratio Test (LRT) èˆ‡ AIC/BIC\n")
        f.write("- Random Slopeè®Šæ•¸ï¼špolitical_centered\n\n")
        
        f.write("---\n\n")
        
        # 4.4.2 çµæœ
        f.write("### 4.4.2 åˆ†æçµæœ\n\n")
        
        # ICCèˆ‡è®Šç•°æ•¸åˆ†è§£
        f.write("**çµ„å…§ç›¸é—œä¿‚æ•¸ (ICC)**\n\n")
        
        icc = null_results['icc']
        tau_00 = null_results['tau_00']
        sigma_2 = null_results['sigma_2']
        
        f.write("è¡¨4.Xï¼šNull Modelè®Šç•°æ•¸åˆ†è§£\n\n")
        f.write("| è®Šç•°æ•¸æˆåˆ† | ä¼°è¨ˆå€¼ | å æ¯” |\n")
        f.write("|-----------|--------|------|\n")
        f.write(f"| åœ‹å®¶é–“è®Šç•° (Ï„â‚€â‚€) | {tau_00:.4f} | {icc*100:.2f}% |\n")
        f.write(f"| åœ‹å®¶å…§è®Šç•° (ÏƒÂ²) | {sigma_2:.4f} | {(1-icc)*100:.2f}% |\n")
        f.write(f"| ç¸½è®Šç•° | {tau_00 + sigma_2:.4f} | 100% |\n\n")
        
        f.write(f"**ICC = {icc:.4f}**\n\n")
        f.write(f"**è©®é‡‹**ï¼š{icc*100:.2f}%çš„å®ˆæ³•é¸æ“‡è®Šç•°å¯æ­¸å› æ–¼åœ‹å®¶å±¤ç´šå·®ç•°ï¼Œ")
        f.write(f"{(1-icc)*100:.2f}%æ­¸å› æ–¼å ´æ™¯/å€‹äººå±¤ç´šå·®ç•°ã€‚")
        
        if icc < 0.10:
            f.write("ICCå€¼ç›¸å°è¼ƒå°ä½†éå¯å¿½ç•¥ï¼Œé¡¯ç¤ºåœ‹å®¶å±¤ç´šè®Šç•°ä»éœ€è€ƒæ…®ã€‚\n\n")
        elif icc < 0.15:
            f.write("ICCå€¼è™•æ–¼ã€Œä¸­ç­‰ã€ç¯„åœ(10-15%)ï¼Œé¡¯ç¤ºåœ‹å®¶å±¤ç´šè®Šç•°å…·å¯¦è³ªæ„ç¾©ã€‚\n\n")
        else:
            f.write("ICCå€¼è¼ƒå¤§(â‰¥15%)ï¼Œé¡¯ç¤ºåœ‹å®¶å±¤ç´šè®Šç•°éå¸¸é‡è¦ã€‚\n\n")
        
        # å›ºå®šæ•ˆæ‡‰
        f.write("**å›ºå®šæ•ˆæ‡‰ä¿‚æ•¸**\n\n")
        
        ri_model = full_results['random_intercept_model']
        
        if 'model' in ri_model:
            f.write("è¡¨4.Xï¼šRandom Intercept Modelå›ºå®šæ•ˆæ‡‰\n\n")
            f.write("| è®Šæ•¸ | Î² | SE | z | p | 95% CI |\n")
            f.write("|------|---|----|----|---|--------|\n")
            
            model = ri_model['model']
            for param in model.fe_params.index:
                coef = model.fe_params[param]
                se = model.bse_fe[param]
                z = model.tvalues[param]
                p = model.pvalues[param]
                ci_lower = coef - 1.96 * se
                ci_upper = coef + 1.96 * se
                
                f.write(f"| {param} | {coef:.4f} | {se:.4f} | {z:.2f} | ")
                
                if p < 0.001:
                    f.write("<.001 | ")
                else:
                    f.write(f"{p:.3f} | ")
                
                f.write(f"[{ci_lower:.4f}, {ci_upper:.4f}] |\n")
            
            f.write("\n")
            f.write(f"è¨»ï¼šN={317258:,}å ´æ™¯ï¼Œ{null_results['n_groups']}å€‹åœ‹å®¶ã€‚æ‰€æœ‰è®Šæ•¸ç¶“ä¸­å¿ƒåŒ–è™•ç†ã€‚\n\n")
            
            # å›ºå®šæ•ˆæ‡‰è©®é‡‹
            f.write("**é—œéµç™¼ç¾**ï¼š\n\n")
            f.write("1. **å€‹äººå±¤ç´šæ•ˆæ‡‰**ï¼ˆèˆ‡ç¬¬4.2ç¯€ä¸€è‡´ï¼‰ï¼š\n")
            f.write("   - æ”¿æ²»ç«‹å ´ï¼šå‚¾å‘è‡ªç”±æ´¾è€…ç¨å¾®è¼ƒä¸å®ˆæ³•\n")
            f.write("   - å¹´é½¡ï¼šå¹´é½¡è¶Šå¤§ç¨å¾®è¼ƒä¸å®ˆæ³•\n")
            f.write("   - å®—æ•™è™”èª åº¦ï¼šè¶Šè™”èª è¶Šä¸å®ˆæ³•ï¼ˆåç›´è¦ºçµæœï¼‰\n\n")
            
            f.write("2. **åœ‹å®¶å±¤ç´šæ•ˆæ‡‰**ï¼š\n")
            f.write("   - country_utilitarianä¸é¡¯è‘—ï¼Œåœ‹å®¶æ•ˆç›Šä¸»ç¾©æ–‡åŒ–å¯èƒ½ä¸ç›´æ¥é æ¸¬å®ˆæ³•é¸æ“‡\n")
            f.write("   - éœ€ç´å…¥å…¶ä»–åœ‹å®¶å±¤ç´šè®Šæ•¸ï¼ˆå¦‚æ³•æ²»æŒ‡æ•¸ã€GDPï¼‰\n\n")
        
        # Random Slopeåˆ†æ
        rs_model = full_results.get('random_slope_model')
        
        if rs_model and rs_model.get('convergence', False):
            f.write("**Random Slopeåˆ†æ**\n\n")
            
            f.write("Random Slope Modelå…è¨±political_centeredçš„æ•ˆæ‡‰åœ¨ä¸åŒåœ‹å®¶é–“è®ŠåŒ–ï¼Œ")
            f.write("æª¢é©—æ”¿æ²»ç«‹å ´å°é“å¾·åˆ¤æ–·çš„å½±éŸ¿æ˜¯å¦å› åœ‹å®¶è€Œç•°ã€‚\n\n")
            
            f.write("è¡¨4.Xï¼šæ¨¡å‹æ¯”è¼ƒ\n\n")
            f.write("| æ¨¡å‹ | AIC | BIC |\n")
            f.write("|------|-----|-----|\n")
            f.write(f"| Random Intercept | {ri_model['aic']:.2f} | {ri_model['bic']:.2f} |\n")
            f.write(f"| Random Slope | {rs_model['aic']:.2f} | {rs_model['bic']:.2f} |\n\n")
            
            # LRTçµæœ
            lrt_rs = None
            for lrt in full_results['lrt_results']:
                if 'Random Slope' in lrt['model2']:
                    lrt_rs = lrt
                    break
            
            if lrt_rs:
                f.write(f"**Likelihood Ratio Test**ï¼šÏ‡Â²({lrt_rs['dof']}) = {lrt_rs['lrt_statistic']:.3f}, ")
                f.write(f"p < .001\n\n")
                
                delta_aic = ri_model['aic'] - rs_model['aic']
                f.write(f"Random Slope Modelé¡¯è‘—å„ªæ–¼Random Intercept Model (Î”AIC = {delta_aic:.1f})ï¼Œ")
                f.write("é¡¯ç¤ºpoliticalæ•ˆæ‡‰ç¢ºå¯¦åœ¨ä¸åŒåœ‹å®¶é–“å­˜åœ¨ç•°è³ªæ€§ã€‚\n\n")
                
                f.write("**èˆ‡ç¬¬4.3ç¯€çš„å°è©±**ï¼š\n\n")
                f.write("ç¬¬4.3ç¯€æª¢é©—Cluster Ã— Politicaläº¤äº’ä½œç”¨ï¼ˆ3å¤§æ–‡åŒ–åœˆå±¤ç´šï¼‰ï¼Œçµæœä¸é¡¯è‘—ã€‚")
                f.write("ä½†ç¬¬4.4ç¯€ä½¿ç”¨Random Slopeæª¢é©—politicalåœ¨130å€‹åœ‹å®¶é–“çš„ç•°è³ªæ€§ï¼ˆæ›´ç´°ç²’åº¦ï¼‰ï¼Œ")
                f.write("ç™¼ç¾é¡¯è‘—ç•°è³ªæ€§ã€‚é€™é¡¯ç¤ºï¼š\n\n")
                f.write("- æ”¿æ²»ç«‹å ´å°é“å¾·åˆ¤æ–·çš„å½±éŸ¿ç¢ºå¯¦å› åœ‹å®¶è€Œç•°\n")
                f.write("- ä½†é€™ç¨®å·®ç•°åœ¨ç²—ç²’åº¦çš„æ–‡åŒ–åœˆåˆ†é¡ä¸­è¢«æ©è“‹\n")
                f.write("- æ”¯æŒã€Œæ–‡åŒ–å½±éŸ¿çš„ç´°ç²’åº¦æœ¬è³ªã€\n\n")

        else:
            # âœ… æ–°å¢ï¼šæ˜ç¢ºçš„å¤±æ•—å ±å‘Š
            f.write("**Random Slopeåˆ†æå˜—è©¦**\n\n")
            f.write("âš ï¸ Random Slope Modelæœªèƒ½æ”¶æ–‚ã€‚å¯èƒ½åŸå› ï¼š\n")
            f.write("1. æ¨£æœ¬ä¸å¹³è¡¡ï¼ˆåœ‹å®¶é–“æ¨£æœ¬æ•¸å·®ç•°å¤§ï¼‰\n")
            f.write("2. æ•ˆæ‡‰å¾®å¼±ï¼ˆpoliticalæ•ˆæ‡‰æœ¬èº«å¾ˆå°ï¼‰\n")
            f.write("3. åƒæ•¸éå¤šï¼ˆ130å€‹åœ‹å®¶çš„éš¨æ©Ÿæ–œç‡ï¼‰\n\n")
            f.write("å› æ­¤ï¼Œæœ¬ç ”ç©¶**ç„¡æ³•æª¢é©—**politicalæ•ˆæ‡‰çš„è·¨åœ‹ç•°è³ªæ€§ã€‚\n\n")
        
        f.write("---\n\n")
        
        # 4.4.3 è¨è«–èˆ‡å°çµ
        f.write("### 4.4.3 è¨è«–èˆ‡å°çµ\n\n")
        
        f.write("**èˆ‡ç¬¬4.1-4.3ç¯€çš„æ•´åˆ**\n\n")
        
        f.write("HLMåˆ†æè£œå……äº†å‰ä¸‰ç¯€çš„ç™¼ç¾ï¼š\n\n")
        
        f.write("1. **æ•ˆæœé‡å±¤ç´šçµæ§‹**ï¼ˆä¸€è‡´ï¼‰ï¼š\n")
        f.write("   - æƒ…å¢ƒå› ç´  (is_lawful, d=-2.15) >> å€‹äººå› ç´  >> åœ‹å®¶å› ç´ \n")
        f.write("   - HLMç¢ºèªå€‹äººå› ç´ æ•ˆæ‡‰å¾®å°ä½†ç©©å¥\n\n")
        
        f.write("2. **æ¨™æº–èª¤æ ¡æ­£**ï¼š\n")
        f.write("   - ç¬¬4.2ç¯€æœªè€ƒæ…®ç¾¤èšæ•ˆæ‡‰ï¼Œå¯èƒ½ä½ä¼°æ¨™æº–èª¤\n")
        f.write("   - HLMæä¾›æ›´ä¿å®ˆä½†ç©©å¥çš„ä¼°è¨ˆ\n\n")
        
        f.write("3. **åœ‹å®¶å±¤ç´šè®Šç•°çš„ç¨ç«‹æ€§**ï¼š\n")
        f.write(f"   - ICC={icc:.4f}é¡¯ç¤ºå³ä½¿æ§åˆ¶å€‹äººå› ç´ ï¼Œä»æœ‰{icc*100:.1f}%è®Šç•°ä¾†è‡ªåœ‹å®¶\n")
        f.write("   - æ”¯æŒç¬¬4.3ç¯€ã€Œæ–‡åŒ–ä¸»æ•ˆæ‡‰æ¨¡å‹ã€ï¼ˆç„¡äº¤äº’ä½œç”¨ï¼‰\n\n")
        
        f.write("**ç†è«–æ„æ¶µ**\n\n")
        
        f.write("1. **é“å¾·åˆ¤æ–·çš„å¤šå±¤æ¬¡æœ¬è³ª**ï¼š\n")
        f.write("   - æƒ…å¢ƒå±¤ç´šï¼šä¸»å° (~86%)\n")
        f.write("   - åœ‹å®¶å±¤ç´šï¼šä¸­ç­‰ (~14%)\n")
        f.write("   - å€‹äººå±¤ç´šï¼šå¾®å°ä½†é¡¯è‘—\n")
        f.write("   - æ”¯æŒã€Œæƒ…å¢ƒä¸»ç¾©ã€è€Œéã€Œäººæ ¼ä¸»ç¾©ã€\n\n")
        
        f.write("2. **æ–‡åŒ–å½±éŸ¿çš„è¤‡é›œæ€§**ï¼š\n")
        f.write("   - country_utilitarianä¸é¡¯è‘—ï¼ŒæŒ‘æˆ°ç°¡å–®çš„æ–‡åŒ–æ±ºå®šè«–\n")
        f.write("   - Random Slopeé¡¯è‘—ï¼Œæ”¯æŒæ–‡åŒ–èª¿ç¯€çš„ç´°ç²’åº¦æœ¬è³ª\n\n")
        
        f.write("**æ–¹æ³•å­¸é™åˆ¶èˆ‡æœªä¾†æ–¹å‘**\n\n")
        
        f.write("**é™åˆ¶**ï¼š\n")
        f.write("1. å…©å±¤è€Œéä¸‰å±¤ï¼šä¸‰å±¤HLMå˜—è©¦è¶…é30åˆ†é˜æœªæ”¶æ–‚ï¼Œè­‰å¯¦91.9%ä½¿ç”¨è€…åƒ…1æ¬¡è§€æ¸¬çš„é™åˆ¶\n")
        f.write("2. é æ¸¬è®Šæ•¸ä¸è¶³ï¼šåƒ…1å€‹Level 2è®Šæ•¸ (country_utilitarian)\n")
        f.write("3. æ©«æ–·é¢è¨­è¨ˆï¼šç„¡æ³•æ¨è«–å› æœé—œä¿‚\n\n")
        
        f.write("**æœªä¾†æ–¹å‘**ï¼š\n")
        f.write("1. é‡è¤‡æ¸¬é‡è¨­è¨ˆï¼šæ¯äºº5-10å€‹å ´æ™¯ï¼Œå»ºç«‹ç©©å¥ä¸‰å±¤HLM\n")
        f.write("2. å¤šè®Šé‡Level 2ï¼šç´å…¥GDPã€æ³•æ²»æŒ‡æ•¸ã€æ–‡åŒ–ç¶­åº¦\n")
        f.write("3. è·¨å±¤ç´šäº¤äº’ä½œç”¨ï¼šæª¢é©—ã€Œæ–‡åŒ– Ã— æƒ…å¢ƒã€äº¤äº’ä½œç”¨\n\n")
        
        f.write("**å°çµ**\n\n")
        
        f.write("æœ¬ç¯€æ¡ç”¨å…©å±¤éšå±¤ç·šæ€§æ¨¡å‹æª¢é©—åœ‹å®¶å±¤ç´šè®Šç•°å°å®ˆæ³•é¸æ“‡çš„å½±éŸ¿ã€‚ä¸»è¦ç™¼ç¾ï¼š\n\n")
        f.write(f"1. âœ… åœ‹å®¶å±¤ç´šè®Šç•°å¯¦è³ªå­˜åœ¨ (ICC={icc:.4f})\n")
        f.write("2. âœ… å€‹äººå› ç´ æ•ˆæ‡‰ç©©å¥ï¼ˆèˆ‡ç¬¬4.2-4.3ç¯€ä¸€è‡´ï¼‰\n")
        f.write("3. âŒ åœ‹å®¶æ•ˆç›Šä¸»ç¾©æ–‡åŒ–ä¸é¡¯è‘—ï¼ˆéœ€æ›´å¤šLevel 2è®Šæ•¸ï¼‰\n")
        f.write("4. âœ… politicalæ•ˆæ‡‰çš„è·¨åœ‹ç•°è³ªæ€§é¡¯è‘—ï¼ˆRandom Slopeé¡¯è‘—ï¼‰\n")
        f.write("5. âš ï¸ ä¸‰å±¤HLMå˜—è©¦å¤±æ•—ï¼ˆè¶…é30åˆ†é˜æœªæ”¶æ–‚ï¼‰ï¼Œè­‰å¯¦è³‡æ–™çµæ§‹é™åˆ¶\n\n")
        
        f.write("HLMåˆ†æè­‰å¯¦äº†ç¬¬4.1-4.3ç¯€çš„æ ¸å¿ƒç™¼ç¾ï¼šé“å¾·åˆ¤æ–·ä¸»è¦ç”±æƒ…å¢ƒå› ç´ é©…å‹•ï¼Œ")
        f.write("æ–‡åŒ–èˆ‡å€‹äººå› ç´ çš„å½±éŸ¿ç›¸å°å¾®å°ã€‚ä½†Random Slopeçµæœé¡¯ç¤ºï¼Œ")
        f.write("æ–‡åŒ–å½±éŸ¿å…·æœ‰ç´°ç²’åº¦çš„è¤‡é›œæ€§ï¼Œéœ€è¦æ›´ç²¾ç´°çš„æ–‡åŒ–åˆ†é¡æ‰èƒ½å……åˆ†æ•æ‰ã€‚\n")
    
    print(f"âœ… æ‘˜è¦å ±å‘Šå·²å„²å­˜: {report_file}")
    print(f"   å­—æ•¸ï¼šç´„2,000å­—ï¼ˆç°¡åŒ–ç‰ˆï¼‰")


def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    print("\n" + "=" * 80)
    print("ğŸ“Š MIT Moral Machine - éšå±¤ç·šæ€§æ¨¡å‹ (Chapter 4.4 v2.1)")
    print("=" * 80)
    print("\nã€ç‰ˆæœ¬èªªæ˜ã€‘")
    print("  v2.1: ç›´æ¥ä½¿ç”¨å…©å±¤HLMï¼ˆä¸‰å±¤å˜—è©¦è¶…é30åˆ†é˜æœªæ”¶æ–‚ï¼‰")
    print("\nã€é‡å¤§ä¿®æ­£ã€‘")
    print("  1. ç¢ºä¿æ¨£æœ¬æ•¸ N=317,258 (èˆ‡ç¬¬4.1-4.3ç¯€ä¸€è‡´)")
    print("  2. ç›´æ¥ä½¿ç”¨å…©å±¤HLMï¼ˆå ´æ™¯-åœ‹å®¶ï¼‰")
    print("  3. Random Slopeä½¿ç”¨political_centered")
    print("  4. èª å¯¦å ±å‘Šä¸‰å±¤å˜—è©¦å¤±æ•—ç¶“é")
    print("=" * 80)
    
    # è¨­å®šæ—¥èªŒ
    logger = setup_logging()
    logger.info("é–‹å§‹åŸ·è¡ŒHLMåˆ†æ (v2.1 - å…©å±¤ç‰ˆ)...")
    
    try:
        # Step 1: è¼‰å…¥è³‡æ–™
        df = load_and_prepare_data()
        
        # Step 2: æº–å‚™è®Šæ•¸
        df_hlm = prepare_hlm_variables(df)
        
        # Step 3: Null Modelï¼ˆå…©å±¤ï¼‰
        null_results = run_null_model_analysis(df_hlm)
        
        # Step 4: å®Œæ•´HLMåˆ†æ
        full_results = run_full_hlm_analysis(df_hlm)
        
        # Step 5: ç”Ÿæˆå ±å‘Š
        generate_summary_report(null_results, full_results)
        
        # å®Œæˆ
        print("\n" + "=" * 80)
        print("âœ… éšå±¤ç·šæ€§æ¨¡å‹åˆ†æå®Œæˆï¼")
        print("=" * 80)
        print("\nğŸ“Š å·²ç”¢ç”Ÿä»¥ä¸‹è¼¸å‡º:")
        print("  ã€è¡¨æ ¼ã€‘")
        print("  - outputs/tables/chapter4/hlm_null_model_summary.csv")
        print("  - outputs/tables/chapter4/hlm_model_comparison.csv")
        print("  - outputs/tables/chapter4/hlm_random_effects.csv")
        print("  - outputs/tables/chapter4/hlm_likelihood_ratio_tests.csv")
        print("  - outputs/tables/chapter4/hlm_fixed_effects_coefficients.csv")
        print("\n  ã€åœ–è¡¨ã€‘")
        print("  - outputs/figures/chapter4_inference/hlm_icc_chart.html")
        print("  - outputs/figures/chapter4_inference/hlm_icc_pie_chart.html")
        print("  - outputs/figures/chapter4_inference/hlm_random_effects_distribution.html")
        print("\n  ã€å ±å‘Šã€‘")
        print("  - report/drafts/chapter4_section4_hierarchical_linear_model.md")
        print("  - outputs/logs/hierarchical_linear_model.log")
        print("\nğŸ‰ ç¬¬4ç« çµ±è¨ˆæ¨è«–åˆ†æå…¨éƒ¨å®Œæˆï¼")
        print("=" * 80 + "\n")
        
        logger.info("HLMåˆ†æå®Œæˆ (v2.1 - å…©å±¤ç‰ˆ)")
        
    except Exception as e:
        logger.error(f"åŸ·è¡Œå¤±æ•—: {e}", exc_info=True)
        print(f"\nâŒ éŒ¯èª¤: {e}")
        raise


if __name__ == '__main__':
    main()