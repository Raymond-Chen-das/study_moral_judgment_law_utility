"""
ç¬¬5ç«  ç¬¬3ç¯€ï¼šå…¨çƒé“å¾·å…‰è­œè¦–è¦ºåŒ–
================================
ä»¥æ•ˆç›Šä¸»ç¾© vs å®ˆæ³•åå¥½å»ºæ§‹å…¨çƒé“å¾·ç©ºé–“

åŸ·è¡Œæ­¤è…³æœ¬å‰è«‹ç¢ºèªï¼š
1. åŸå§‹è³‡æ–™ CountriesChangePr.csv ä½æ–¼ data/raw/
2. åŸå§‹è³‡æ–™ country_cluster_map.csv ä½æ–¼ data/raw/

ç”¢å‡ºï¼š
- outputs/figures/chapter5/moral_spectrum_global.html
- outputs/figures/chapter5/cluster_centroids.html
- outputs/tables/chapter5/moral_spectrum_coordinates.csv
- outputs/tables/chapter5/quadrant_distribution.csv
- report/drafts/chapter5_section3_moral_spectrum.md
"""

import os
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

import pandas as pd
import numpy as np

# å°å…¥è‡ªå®šç¾©æ¨¡çµ„
from src.analysis.integration.moral_spectrum import (
    MoralSpectrumAnalyzer, load_and_analyze
)
from src.visualization.chapter5.chapter5_plots import (
    plot_moral_spectrum,
    plot_cluster_centroids
)


def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    
    print("=" * 70)
    print("ç¬¬5ç«  ç¬¬3ç¯€ï¼šå…¨çƒé“å¾·å…‰è­œè¦–è¦ºåŒ–")
    print(f"åŸ·è¡Œæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # ========================================
    # 1. è¨­å®šè·¯å¾‘
    # ========================================
    
    # è¼¸å…¥è·¯å¾‘
    AMCE_PATH = PROJECT_ROOT / "data/raw/CountriesChangePr.csv"
    CLUSTER_PATH = PROJECT_ROOT / "data/raw/country_cluster_map.csv"
    
    # è¼¸å‡ºè·¯å¾‘
    OUTPUT_FIG_DIR = PROJECT_ROOT / "outputs/figures/chapter5"
    OUTPUT_TABLE_DIR = PROJECT_ROOT / "outputs/tables/chapter5"
    REPORT_DIR = PROJECT_ROOT / "report/drafts"
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    OUTPUT_FIG_DIR.mkdir(parents=True, exist_ok=True)
    OUTPUT_TABLE_DIR.mkdir(parents=True, exist_ok=True)
    REPORT_DIR.mkdir(parents=True, exist_ok=True)
    
    # æª¢æŸ¥è¼¸å…¥æª”æ¡ˆ
    if not AMCE_PATH.exists():
        print(f"\nâŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° AMCE è³‡æ–™æª”æ¡ˆ")
        print(f"   é æœŸè·¯å¾‘: {AMCE_PATH}")
        return
    
    if not CLUSTER_PATH.exists():
        print(f"\nâŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ–‡åŒ–åœˆåˆ†é¡æª”æ¡ˆ")
        print(f"   é æœŸè·¯å¾‘: {CLUSTER_PATH}")
        return
    
    print(f"\nâœ… è¼¸å…¥æª”æ¡ˆç¢ºèªå®Œæˆ")
    
    # ========================================
    # 2. è¼‰å…¥èˆ‡åˆ†æ
    # ========================================
    
    analyzer, spectrum_data = load_and_analyze(
        amce_path=str(AMCE_PATH),
        cluster_path=str(CLUSTER_PATH),
        verbose=True
    )
    
    # ç²å–å„ç¨®åˆ†æçµæœ
    taiwan_analysis = analyzer.get_taiwan_analysis()
    centroids = analyzer.get_cluster_centroids()
    cultural_distance = analyzer.compute_cultural_distance()
    
    # ========================================
    # 3. è¦–è¦ºåŒ–
    # ========================================
    
    print("\n" + "=" * 60)
    print("ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨")
    print("=" * 60)
    
    # ç²å–åœ‹å®¶ä½ç½®è³‡æ–™
    country_positions = analyzer.get_country_positions()
    
    # å…¨çƒé“å¾·å…‰è­œ
    fig_spectrum = plot_moral_spectrum(
        spectrum_data=country_positions,
        output_path=str(OUTPUT_FIG_DIR / "moral_spectrum_global.html"),
        title="å…¨çƒé“å¾·å…‰è­œï¼šæ•ˆç›Šä¸»ç¾© vs å®ˆæ³•åå¥½"
    )
    
    # æ–‡åŒ–åœˆé‡å¿ƒ
    fig_centroids = plot_cluster_centroids(
        spectrum_data=country_positions,
        output_path=str(OUTPUT_FIG_DIR / "cluster_centroids.html"),
        title="æ–‡åŒ–åœˆé‡å¿ƒæ¯”è¼ƒ"
    )
    
    # ========================================
    # 4. å„²å­˜è¡¨æ ¼
    # ========================================
    
    print("\n" + "=" * 60)
    print("å„²å­˜åˆ†æè¡¨æ ¼")
    print("=" * 60)
    
    # åœ‹å®¶åº§æ¨™
    country_positions.to_csv(
        OUTPUT_TABLE_DIR / "moral_spectrum_coordinates.csv",
        index=False,
        encoding='utf-8-sig'
    )
    print(f"âœ… å·²å„²å­˜: moral_spectrum_coordinates.csv")
    
    # è±¡é™åˆ†ä½ˆ
    if analyzer.quadrant_stats is not None:
        analyzer.quadrant_stats.to_csv(
            OUTPUT_TABLE_DIR / "quadrant_distribution.csv",
            index=False,
            encoding='utf-8-sig'
        )
        print(f"âœ… å·²å„²å­˜: quadrant_distribution.csv")
    
    # æ–‡åŒ–åœˆè·é›¢çŸ©é™£
    cultural_distance.to_csv(
        OUTPUT_TABLE_DIR / "cultural_distance_matrix.csv",
        encoding='utf-8-sig'
    )
    print(f"âœ… å·²å„²å­˜: cultural_distance_matrix.csv")
    
    # ========================================
    # 5. ç”Ÿæˆå ±å‘Šè‰ç¨¿
    # ========================================
    
    print("\n" + "=" * 60)
    print("ç”Ÿæˆå ±å‘Šè‰ç¨¿")
    print("=" * 60)
    
    report_content = generate_section_report(
        analyzer=analyzer,
        taiwan_analysis=taiwan_analysis,
        centroids=centroids,
        cultural_distance=cultural_distance,
        country_positions=country_positions
    )
    
    report_path = REPORT_DIR / "chapter5_section3_moral_spectrum.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    print(f"âœ… å·²å„²å­˜: {report_path}")
    
    # ========================================
    # 6. ç¸½çµ
    # ========================================
    
    print("\n" + "=" * 70)
    print("ç¬¬5.3ç¯€åŸ·è¡Œå®Œæˆï¼")
    print("=" * 70)
    
    print("\nğŸ“Š ç”¢å‡ºæª”æ¡ˆï¼š")
    print(f"   - {OUTPUT_FIG_DIR / 'moral_spectrum_global.html'}")
    print(f"   - {OUTPUT_FIG_DIR / 'cluster_centroids.html'}")
    print(f"   - {OUTPUT_TABLE_DIR / 'moral_spectrum_coordinates.csv'}")
    print(f"   - {OUTPUT_TABLE_DIR / 'quadrant_distribution.csv'}")
    print(f"   - {OUTPUT_TABLE_DIR / 'cultural_distance_matrix.csv'}")
    
    print("\nğŸ”‘ é—œéµç™¼ç¾ï¼š")
    print(f"   å°ç£å®šä½:")
    print(f"   - æ•ˆç›Šä¸»ç¾©: {taiwan_analysis['utilitarian']:.3f} (æ’å {taiwan_analysis['util_rank']}/{taiwan_analysis['total_countries']})")
    print(f"   - å®ˆæ³•åå¥½: {taiwan_analysis['law_preference']:.3f} (æ’å {taiwan_analysis['law_rank']}/{taiwan_analysis['total_countries']})")
    print(f"   - è±¡é™: {taiwan_analysis['quadrant']}")
    
    print("\n   æ–‡åŒ–åœˆé‡å¿ƒ:")
    for _, row in centroids.iterrows():
        print(f"   - {row['Cluster_Name']}: æ•ˆç›Š={row['utilitarian']:.3f}, å®ˆæ³•={row['law_preference']:.3f}")


def generate_section_report(
    analyzer: MoralSpectrumAnalyzer,
    taiwan_analysis: dict,
    centroids: pd.DataFrame,
    cultural_distance: pd.DataFrame,
    country_positions: pd.DataFrame
) -> str:
    """ç”Ÿæˆ 5.3 ç¯€å ±å‘Šè‰ç¨¿"""
    
    report = []
    report.append("## 5.3 å…¨çƒé“å¾·å…‰è­œè¦–è¦ºåŒ–\n")
    report.append(f"**åˆ†ææ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    report.append("### è¦–è¦ºåŒ–æ¡†æ¶\n")
    report.append("ä»¥äºŒç¶­ç©ºé–“å‘ˆç¾ 130 å€‹åœ‹å®¶çš„é“å¾·åå¥½å®šä½ï¼š")
    report.append("- **Xè»¸**ï¼šæ•ˆç›Šä¸»ç¾© AMCEï¼ˆæ•¸é‡åå¥½ï¼šæ‹¯æ•‘å¤šæ•¸ vs å°‘æ•¸ï¼‰")
    report.append("- **Yè»¸**ï¼šå®ˆæ³•åå¥½ AMCEï¼ˆè¦å‰‡éµå¾ªï¼šå®ˆæ³•è€… vs é•æ³•è€…ï¼‰")
    report.append("- **é¡è‰²**ï¼šæ–‡åŒ–åœˆï¼ˆWestern / Eastern / Southernï¼‰")
    report.append("- **è±¡é™**ï¼šä»¥å…¨çƒå¹³å‡ç‚ºåŸé»åŠƒåˆ†å››è±¡é™\n")
    
    report.append("### æ–‡åŒ–åœˆé‡å¿ƒ\n")
    report.append("| æ–‡åŒ–åœˆ | åœ‹å®¶æ•¸ | æ•ˆç›Šä¸»ç¾© | å®ˆæ³•åå¥½ |")
    report.append("|--------|--------|----------|----------|")
    for _, row in centroids.iterrows():
        report.append(f"| {row['Cluster_Name']} | {int(row['n_countries'])} | {row['utilitarian']:.3f} | {row['law_preference']:.3f} |")
    report.append("")
    
    report.append("### æ–‡åŒ–åœˆé–“é“å¾·è·é›¢\n")
    report.append("| | Western | Eastern | Southern |")
    report.append("|---|---------|---------|----------|")
    for cluster in ['Western', 'Eastern', 'Southern']:
        row_str = f"| {cluster} |"
        for other in ['Western', 'Eastern', 'Southern']:
            row_str += f" {cultural_distance.loc[cluster, other]:.3f} |"
        report.append(row_str)
    report.append("")
    
    report.append("### å°ç£å®šä½åˆ†æ\n")
    report.append(f"- **æ•ˆç›Šä¸»ç¾©**: {taiwan_analysis['utilitarian']:.3f}")
    report.append(f"  - å…¨çƒæ’å: {taiwan_analysis['util_rank']}/{taiwan_analysis['total_countries']}")
    report.append(f"- **å®ˆæ³•åå¥½**: {taiwan_analysis['law_preference']:.3f}")
    report.append(f"  - å…¨çƒæ’å: {taiwan_analysis['law_rank']}/{taiwan_analysis['total_countries']}")
    report.append(f"- **æ‰€å±¬è±¡é™**: {taiwan_analysis['quadrant']}\n")
    
    report.append("**æœ€è¿‘é„°å±…ï¼ˆé“å¾·è·é›¢ï¼‰**ï¼š")
    for nb in taiwan_analysis['nearest_neighbors']:
        report.append(f"- {nb['Country']} ({nb['UserCountry3']}): {nb['distance_to_taiwan']:.4f}")
    report.append("")
    
    report.append("### è±¡é™åˆ†ä½ˆ\n")
    quadrant_counts = country_positions.groupby(['quadrant', 'Cluster_Name']).size().unstack(fill_value=0)
    report.append(quadrant_counts.to_markdown())
    report.append("")
    
    report.append("### é—œéµç™¼ç¾\n")
    report.append("1. **æ–‡åŒ–åœˆå·®ç•°**ï¼šä¸‰å¤§æ–‡åŒ–åœˆåœ¨é“å¾·å…‰è­œä¸Šæœ‰æ˜é¡¯çš„ç©ºé–“åˆ†é›¢")
    report.append("   - Eastern å‚¾å‘é«˜å®ˆæ³•")
    report.append("   - Western å‚¾å‘é«˜æ•ˆç›Šä¸»ç¾©")
    report.append("   - Southern ä½æ–¼ä¸­é–“åœ°å¸¶\n")
    
    report.append("2. **å°ç£å®šä½**ï¼š")
    report.append(f"   - ä½æ–¼ã€Œ{taiwan_analysis['quadrant']}ã€è±¡é™")
    report.append("   - æœ€æ¥è¿‘çš„é„°å±…åŒ…å«æ±äºèˆ‡æ±å—äºåœ‹å®¶")
    report.append("   - é©—è­‰ç¬¬3ç« ã€Œæ±äº-æ±å—äºæ ¸å¿ƒã€çš„åˆ†ç¾¤çµæœ\n")
    
    report.append("3. **å…¨ç ”ç©¶æ•´åˆæ„ç¾©**ï¼š")
    report.append("   - æ­¤è¦–è¦ºåŒ–æ•´åˆäº†ç¬¬3ç« ï¼ˆæ¢ç´¢åˆ†æï¼‰èˆ‡ç¬¬4ç« ï¼ˆçµ±è¨ˆæ¨è«–ï¼‰çš„ç™¼ç¾")
    report.append("   - åœ‹å®¶å±¤ç´šè®Šç•°ï¼ˆICC=0.25%ï¼‰åœ¨äºŒç¶­ç©ºé–“ä¸­æ¸…æ¥šå‘ˆç¾")
    report.append("   - ç‚ºç¬¬6ç« çš„å“²å­¸è¨è«–æä¾›è¦–è¦ºåŒ–åŸºç¤\n")
    
    report.append("### è¦–è¦ºåŒ–çµæœ\n")
    report.append("- [å…¨çƒé“å¾·å…‰è­œ](../outputs/figures/chapter5/moral_spectrum_global.html)")
    report.append("- [æ–‡åŒ–åœˆé‡å¿ƒ](../outputs/figures/chapter5/cluster_centroids.html)\n")
    
    return "\n".join(report)


if __name__ == "__main__":
    main()