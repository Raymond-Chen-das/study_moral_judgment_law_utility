"""
10_logistic_regression.py
=========================
ç¬¬å››ç« ï¼šçµ±è¨ˆæ¨è«– - é‚è¼¯è¿´æ­¸åˆ†æ

åŠŸèƒ½ï¼š
1. å¤šè®Šé‡é‚è¼¯è¿´æ­¸
2. VIFå…±ç·šæ€§è¨ºæ–·
3. æ¨¡å‹æ“¬åˆåº¦æª¢é©—
4. ä¿‚æ•¸èˆ‡Odds Ratioè¦–è¦ºåŒ–

åŸ·è¡Œæ–¹å¼ï¼š
    python scripts/10_logistic_regression.py
"""

import sys
from pathlib import Path

# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„åŠ å…¥è·¯å¾‘
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from src.analysis.inference.logistic_regression import (
    LogisticRegressionAnalysis, 
    run_logistic_regression
)
import pandas as pd
import numpy as np
import logging
from datetime import datetime


def setup_logging(log_dir: str = 'outputs/logs') -> logging.Logger:
    """è¨­å®šæ—¥èªŒ"""
    log_path = Path(log_dir)
    log_path.mkdir(parents=True, exist_ok=True)
    
    log_file = log_path / 'logistic_regression.log'
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, mode='w', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger(__name__)


def load_and_prepare_data(data_path: str = 'data/processed/featured_data.csv') -> pd.DataFrame:
    """
    è¼‰å…¥ä¸¦æº–å‚™åˆ†æè³‡æ–™
    
    Returns:
    --------
    DataFrame : éæ¿¾å¾Œçš„è³‡æ–™
    """
    print("\n" + "="*60)
    print("è¼‰å…¥è³‡æ–™...")
    print("="*60)
    
    df = pd.read_csv(data_path)
    print(f"âœ… åŸå§‹è³‡æ–™: {len(df):,} è¡Œ")
    
    # éæ¿¾ Cluster == -1
    df_filtered = df[df['Cluster'] != -1].copy()
    removed = len(df) - len(df_filtered)
    print(f"âœ… éæ¿¾å¾Œè³‡æ–™: {len(df_filtered):,} è¡Œ")
    print(f"   (ç§»é™¤ {removed:,} è¡Œ Cluster==-1)")
    
    # ç§»é™¤ç¼ºå¤±å€¼
    required_cols = ['chose_lawful', 'Cluster', 'Review_age', 
                    'Review_political', 'Review_religious']
    
    df_clean = df_filtered[required_cols].dropna()
    na_removed = len(df_filtered) - len(df_clean)
    
    print(f"âœ… ç§»é™¤ç¼ºå¤±å€¼å¾Œ: {len(df_clean):,} è¡Œ")
    if na_removed > 0:
        print(f"   (ç§»é™¤ {na_removed:,} è¡Œç¼ºå¤±å€¼, {na_removed/len(df_filtered)*100:.2f}%)")
    
    # æª¢æŸ¥è³‡æ–™åˆ†ä½ˆ
    print(f"\nçµæœè®Šæ•¸åˆ†ä½ˆ:")
    chose_lawful_dist = df_clean['chose_lawful'].value_counts()
    for value, count in chose_lawful_dist.items():
        print(f"  chose_lawful={value}: {count:,} ({count/len(df_clean)*100:.1f}%)")
    
    print(f"\næ–‡åŒ–åœˆåˆ†ä½ˆ:")
    cluster_counts = df_clean['Cluster'].value_counts().sort_index()
    cluster_names = {0: 'Western', 1: 'Eastern', 2: 'Southern'}
    for cluster, count in cluster_counts.items():
        name = cluster_names.get(cluster, str(cluster))
        print(f"  {name}: {count:,} ({count/len(df_clean)*100:.1f}%)")
    
    return df_clean


def prepare_predictors(df: pd.DataFrame) -> tuple:
    """
    æº–å‚™é æ¸¬è®Šæ•¸
    
    Parameters:
    -----------
    df : DataFrame
        è³‡æ–™
        
    Returns:
    --------
    tuple : (æº–å‚™å¥½çš„è³‡æ–™, é æ¸¬è®Šæ•¸åˆ—è¡¨)
    """
    print("\n" + "="*60)
    print("æº–å‚™é æ¸¬è®Šæ•¸...")
    print("="*60)
    
    # å»ºç«‹Clusterçš„dummyè®Šæ•¸ (Westernç‚ºåƒè€ƒçµ„)
    cluster_dummies = pd.get_dummies(df['Cluster'], prefix='Cluster', drop_first=False)
    
    # é¸æ“‡Easternå’ŒSouthernä½œç‚ºé æ¸¬è®Šæ•¸ (Western=åƒè€ƒçµ„)
    # Western: Cluster==0, Eastern: Cluster==1, Southern: Cluster==2
    df_model = df.copy()
    df_model['Cluster_Eastern'] = (df['Cluster'] == 1).astype(int)
    df_model['Cluster_Southern'] = (df['Cluster'] == 2).astype(int)
    
    print("âœ… Clusterè®Šæ•¸ç·¨ç¢¼:")
    print("  åƒè€ƒçµ„: Western (Cluster==0)")
    print("  Cluster_Eastern: 1 if Eastern, 0 otherwise")
    print("  Cluster_Southern: 1 if Southern, 0 otherwise")
    
    # é æ¸¬è®Šæ•¸åˆ—è¡¨
    predictor_vars = [
        'Cluster_Eastern',
        'Cluster_Southern', 
        'Review_age',
        'Review_political',
        'Review_religious'
    ]
    
    print(f"\nâœ… é æ¸¬è®Šæ•¸ ({len(predictor_vars)} å€‹):")
    for var in predictor_vars:
        print(f"  - {var}")
    
    # æè¿°çµ±è¨ˆ
    print(f"\né æ¸¬è®Šæ•¸æè¿°çµ±è¨ˆ:")
    for var in predictor_vars:
        mean_val = df_model[var].mean()
        std_val = df_model[var].std()
        print(f"  {var}: Mean={mean_val:.3f}, SD={std_val:.3f}")
    
    return df_model, predictor_vars


def run_main_logistic_regression(df: pd.DataFrame,
                                 predictor_vars: list,
                                 output_dir: str = 'outputs/tables/chapter4',
                                 figure_dir: str = 'outputs/figures/chapter4_inference') -> dict:
    """
    åŸ·è¡Œä¸»è¦é‚è¼¯è¿´æ­¸åˆ†æ
    
    Parameters:
    -----------
    df : DataFrame
        è³‡æ–™
    predictor_vars : list
        é æ¸¬è®Šæ•¸åˆ—è¡¨
    output_dir : str
        è¡¨æ ¼è¼¸å‡ºç›®éŒ„
    figure_dir : str
        åœ–è¡¨è¼¸å‡ºç›®éŒ„
        
    Returns:
    --------
    dict : åˆ†æçµæœ
    """
    print("\n" + "="*60)
    print("é‚è¼¯è¿´æ­¸åˆ†æ")
    print("="*60)
    
    # åŸ·è¡Œåˆ†æ
    results = run_logistic_regression(
        data=df,
        outcome_var='chose_lawful',
        predictor_vars=predictor_vars,
        alpha=0.05,
        save_dir=None  # ç¨å¾Œæ‰‹å‹•å„²å­˜
    )
    
    # å„²å­˜çµæœ
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    fig_path = Path(figure_dir)
    fig_path.mkdir(parents=True, exist_ok=True)
    
    # 1. ä¿‚æ•¸è¡¨
    coef_df = results['coefficients']
    coef_df.to_csv(
        output_path / 'logistic_regression_coefficients.csv',
        index=False,
        encoding='utf-8-sig'
    )
    print(f"\nâœ… ä¿‚æ•¸è¡¨: {output_path / 'logistic_regression_coefficients.csv'}")
    
    # 2. VIFè¨ºæ–·
    vif_df = results['vif']
    vif_df.to_csv(
        output_path / 'logistic_regression_vif.csv',
        index=False,
        encoding='utf-8-sig'
    )
    print(f"âœ… VIFè¨ºæ–·: {output_path / 'logistic_regression_vif.csv'}")
    
    # 3. æ¨¡å‹æ‘˜è¦
    model_summary = results['model_summary']
    summary_df = pd.DataFrame([model_summary])
    summary_df.to_csv(
        output_path / 'logistic_regression_model_summary.csv',
        index=False,
        encoding='utf-8-sig'
    )
    print(f"âœ… æ¨¡å‹æ‘˜è¦: {output_path / 'logistic_regression_model_summary.csv'}")
    
    # 4. Hosmer-Lemeshowæª¢å®š
    hl_test = results['hosmer_lemeshow']
    hl_df = pd.DataFrame([hl_test])
    hl_df.to_csv(
        output_path / 'logistic_regression_hosmer_lemeshow.csv',
        index=False,
        encoding='utf-8-sig'
    )
    print(f"âœ… H-Læª¢å®š: {output_path / 'logistic_regression_hosmer_lemeshow.csv'}")
    
    # 5. åœ–è¡¨
    results['figures']['coefficient_plot'].write_html(
        str(fig_path / 'logistic_coefficients_plot.html')
    )
    print(f"âœ… ä¿‚æ•¸åœ–: {fig_path / 'logistic_coefficients_plot.html'}")
    
    results['figures']['odds_ratio_plot'].write_html(
        str(fig_path / 'logistic_odds_ratio_plot.html')
    )
    print(f"âœ… ORåœ–: {fig_path / 'logistic_odds_ratio_plot.html'}")
    
    return results


def interpret_results(results: dict) -> dict:
    """
    è§£é‡‹é‚è¼¯è¿´æ­¸çµæœ
    
    Parameters:
    -----------
    results : dict
        åˆ†æçµæœ
        
    Returns:
    --------
    dict : è§£é‡‹æ–‡å­—
    """
    coef_df = results['coefficients']
    model_summary = results['model_summary']
    hl_test = results['hosmer_lemeshow']
    vif_df = results['vif']
    
    interpretation = {}
    
    # 1. æ¨¡å‹æ•´é«”è©•ä¼°
    interpretation['model_fit'] = {
        'pseudo_r2': model_summary['pseudo_r2_mcfadden'],
        'aic': model_summary['aic'],
        'bic': model_summary['bic'],
        'hosmer_lemeshow_p': hl_test['p_value'],
        'good_fit': hl_test['good_fit']
    }
    
    # 2. å…±ç·šæ€§è©•ä¼°
    severe_vif = vif_df[vif_df['å…±ç·šæ€§'] == 'åš´é‡']
    interpretation['multicollinearity'] = {
        'severe_issues': len(severe_vif) > 0,
        'max_vif': vif_df['VIF'].max(),
        'severe_vars': severe_vif['è®Šæ•¸'].tolist() if len(severe_vif) > 0 else []
    }
    
    # 3. é¡¯è‘—é æ¸¬è®Šæ•¸
    sig_predictors = coef_df[(coef_df['é¡¯è‘—']) & (coef_df['è®Šæ•¸'] != 'const')]
    
    interpretation['significant_predictors'] = []
    
    for _, row in sig_predictors.iterrows():
        direction = "å¢åŠ " if row['ä¿‚æ•¸'] > 0 else "æ¸›å°‘"
        
        pred_info = {
            'variable': row['è®Šæ•¸'],
            'coefficient': row['ä¿‚æ•¸'],
            'odds_ratio': row['Odds_Ratio'],
            'p_value': row['på€¼'],
            'ci_lower': row['OR_CI_ä¸‹ç•Œ'],
            'ci_upper': row['OR_CI_ä¸Šç•Œ'],
            'direction': direction,
            'interpretation': f"{row['è®Šæ•¸']}: OR={row['Odds_Ratio']:.3f}, {direction}å®ˆæ³•é¸æ“‡æ©Ÿç‡"
        }
        
        interpretation['significant_predictors'].append(pred_info)
    
    # 4. æ–‡åŒ–åœˆæ•ˆæ‡‰
    cluster_effects = []
    for var in ['Cluster_Eastern', 'Cluster_Southern']:
        if var in coef_df['è®Šæ•¸'].values:
            row = coef_df[coef_df['è®Šæ•¸'] == var].iloc[0]
            cluster_effects.append({
                'cluster': var.replace('Cluster_', ''),
                'vs_reference': 'Western',
                'odds_ratio': row['Odds_Ratio'],
                'significant': row['é¡¯è‘—'],
                'p_value': row['på€¼']
            })
    
    interpretation['cluster_effects'] = cluster_effects
    
    return interpretation


def generate_summary_report(results: dict,
                            interpretation: dict,
                            output_dir: str = 'report/drafts') -> None:
    """
    ç”Ÿæˆæ‘˜è¦å ±å‘Š (Markdownæ ¼å¼)
    
    Parameters:
    -----------
    results : dict
        åˆ†æçµæœ
    interpretation : dict
        çµæœè§£é‡‹
    output_dir : str
        å ±å‘Šè¼¸å‡ºç›®éŒ„
    """
    print("\n" + "="*60)
    print("ç”Ÿæˆæ‘˜è¦å ±å‘Š")
    print("="*60)
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    report_file = output_path / 'chapter4_section2_logistic_regression.md'
    
    coef_df = results['coefficients']
    model_summary = results['model_summary']
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# ç¬¬4ç«  çµ±è¨ˆæ¨è«–\n\n")
        f.write("## 4.2 å¤šè®Šé‡é‚è¼¯è¿´æ­¸åˆ†æ\n\n")
        
        # æ¨¡å‹è¨­å®š
        f.write("### æ¨¡å‹è¨­å®š\n\n")
        f.write("**ä¾è®Šæ•¸**: `chose_lawful` (0=æœªé¸å®ˆæ³•æ–¹, 1=é¸æ“‡å®ˆæ³•æ–¹)\n\n")
        f.write("**è‡ªè®Šæ•¸**:\n")
        f.write("- **æ–‡åŒ–åœˆ**: `Cluster_Eastern`, `Cluster_Southern` (åƒè€ƒçµ„: Western)\n")
        f.write("- **å¹´é½¡**: `Review_age`\n")
        f.write("- **æ”¿æ²»å‚¾å‘**: `Review_political`\n")
        f.write("- **å®—æ•™ä¿¡ä»°**: `Review_religious`\n\n")
        
        # æ¨¡å‹æ‘˜è¦
        f.write("### æ¨¡å‹æ‘˜è¦\n\n")
        f.write(f"- **æ¨£æœ¬æ•¸**: {model_summary['n_obs']:,}\n")
        f.write(f"- **Pseudo RÂ² (McFadden)**: {model_summary['pseudo_r2_mcfadden']:.4f}\n")
        f.write(f"- **AIC**: {model_summary['aic']:.2f}\n")
        f.write(f"- **BIC**: {model_summary['bic']:.2f}\n\n")
        
        # æ“¬åˆåº¦æª¢å®š
        hl_test = results['hosmer_lemeshow']
        f.write("**Hosmer-Lemeshowæ“¬åˆåº¦æª¢å®š**:\n")
        p_str = "< .001" if hl_test['p_value'] < 0.001 else f"= {hl_test['p_value']:.3f}"
        f.write(f"- Ï‡Â²({hl_test['dof']}) = {hl_test['chi2']:.3f}, p {p_str}\n")
        if hl_test['good_fit']:
            f.write("- âœ… æ¨¡å‹æ“¬åˆè‰¯å¥½ (p > 0.05)\n\n")
        else:
            f.write("- âš ï¸  æ¨¡å‹æ“¬åˆå¯èƒ½ä¸ä½³ (p < 0.05)\n\n")
        
        # å…±ç·šæ€§è¨ºæ–·
        f.write("**å…±ç·šæ€§è¨ºæ–· (VIF)**:\n")
        vif_df = results['vif']
        max_vif = vif_df['VIF'].max()
        
        if interpretation['multicollinearity']['severe_issues']:
            f.write(f"- âš ï¸  æª¢æ¸¬åˆ°åš´é‡å…±ç·šæ€§ (VIF > 10)\n")
            for var in interpretation['multicollinearity']['severe_vars']:
                vif_val = vif_df[vif_df['è®Šæ•¸'] == var]['VIF'].values[0]
                f.write(f"  - {var}: VIF = {vif_val:.2f}\n")
        else:
            f.write(f"- âœ… ç„¡åš´é‡å…±ç·šæ€§å•é¡Œ (æœ€å¤§VIF = {max_vif:.2f})\n")
        
        f.write("\n---\n\n")
        
        # ä¿‚æ•¸è¡¨
        f.write("### è¿´æ­¸ä¿‚æ•¸\n\n")
        f.write("| è®Šæ•¸ | ä¿‚æ•¸ | SE | zå€¼ | på€¼ | OR | 95% CI | é¡¯è‘— |\n")
        f.write("|------|------|-----|-----|-----|-----|--------|------|\n")
        
        for _, row in coef_df.iterrows():
            if row['è®Šæ•¸'] == 'const':
                var_name = 'æˆªè·'
            else:
                var_name = row['è®Šæ•¸']
            
            ci = f"[{row['OR_CI_ä¸‹ç•Œ']:.3f}, {row['OR_CI_ä¸Šç•Œ']:.3f}]"
            sig = row['æ˜Ÿè™Ÿ']
            
            p_display = "< .001" if row['på€¼'] < 0.001 else f"{row['på€¼']:.3f}"
            f.write(f"| {var_name} | {row['ä¿‚æ•¸']:.4f} | {row['æ¨™æº–èª¤']:.4f} | "
                f"{row['zå€¼']:.3f} | {p_display} | {row['Odds_Ratio']:.3f} | "
                f"{ci} | {sig} |\n")
        
        f.write("\nè¨»: *** p<0.001, ** p<0.01, * p<0.05\n\n")
        
        f.write("---\n\n")
        
        # çµæœè©®é‡‹
        f.write("### çµæœè©®é‡‹\n\n")
        
        # é¡¯è‘—é æ¸¬è®Šæ•¸
        sig_preds = interpretation['significant_predictors']
        
        if len(sig_preds) > 0:
            f.write("**é¡¯è‘—é æ¸¬è®Šæ•¸**:\n\n")
            
            for pred in sig_preds:
                f.write(f"**{pred['variable']}**:\n")
                f.write(f"- Odds Ratio: {pred['odds_ratio']:.3f} "
                       f"(95% CI: [{pred['ci_lower']:.3f}, {pred['ci_upper']:.3f}])\n")
                p_str = "< .001" if pred['p_value'] < 0.001 else f"= {pred['p_value']:.3f}"
                f.write(f"- p {p_str}\n")
                
                # å¯¦è³ªè§£é‡‹
                if pred['odds_ratio'] > 1:
                    change_pct = (pred['odds_ratio'] - 1) * 100
                    f.write(f"- è§£é‡‹: {pred['variable']}æ¯å¢åŠ 1å–®ä½ï¼Œå®ˆæ³•é¸æ“‡çš„å‹ç®—å¢åŠ {change_pct:.1f}%\n")
                else:
                    change_pct = (1 - pred['odds_ratio']) * 100
                    f.write(f"- è§£é‡‹: {pred['variable']}æ¯å¢åŠ 1å–®ä½ï¼Œå®ˆæ³•é¸æ“‡çš„å‹ç®—æ¸›å°‘{change_pct:.1f}%\n")
                
                f.write("\n")
        else:
            f.write("**ç„¡é¡¯è‘—é æ¸¬è®Šæ•¸** (Î± = 0.05)\n\n")
        
        # æ–‡åŒ–åœˆæ•ˆæ‡‰
        f.write("**æ–‡åŒ–åœˆæ•ˆæ‡‰** (ç›¸å°æ–¼Western):\n\n")
        
        for effect in interpretation['cluster_effects']:
            cluster = effect['cluster']
            or_val = effect['odds_ratio']
            sig = 'âœ“' if effect['significant'] else ''
            
            p_str = "< .001" if effect['p_value'] < 0.001 else f"= {effect['p_value']:.3f}"
            f.write(f"- **{cluster} vs Western**: OR = {or_val:.3f}, p {p_str} {sig}\n")
        
        f.write("\n---\n\n")
        
        # é—œéµç™¼ç¾
        f.write("### é—œéµç™¼ç¾\n\n")
        
        f.write(f"1. **æ¨¡å‹è§£é‡‹åŠ›**: Pseudo RÂ² = {model_summary['pseudo_r2_mcfadden']:.4f}")
        if model_summary['pseudo_r2_mcfadden'] < 0.02:
            f.write(" (æ¥µä½ï¼Œæ¨¡å‹è§£é‡‹åŠ›æœ‰é™)\n")
        elif model_summary['pseudo_r2_mcfadden'] < 0.15:
            f.write(" (ä½ï¼Œç¬¦åˆé“å¾·åˆ¤æ–·çš„è¤‡é›œæ€§)\n")
        else:
            f.write(" (ä¸­ç­‰)\n")
        
        f.write(f"\n2. **é¡¯è‘—è®Šæ•¸æ•¸**: {len(sig_preds)}/{len(coef_df)-1} å€‹é æ¸¬è®Šæ•¸é”é¡¯è‘—\n")
        
        # æª¢æŸ¥æ–‡åŒ–åœˆæ˜¯å¦é¡¯è‘—
        cluster_sig = any(e['significant'] for e in interpretation['cluster_effects'])
        
        if cluster_sig:
            f.write("\n3. **æ–‡åŒ–åœˆæ•ˆæ‡‰**: åœ¨æ§åˆ¶å…¶ä»–è®Šæ•¸å¾Œï¼Œæ–‡åŒ–åœˆå°å®ˆæ³•é¸æ“‡ä»æœ‰ç¨ç«‹å½±éŸ¿\n")
        else:
            f.write("\n3. **æ–‡åŒ–åœˆæ•ˆæ‡‰**: åœ¨æ§åˆ¶å…¶ä»–è®Šæ•¸å¾Œï¼Œæ–‡åŒ–åœˆæ•ˆæ‡‰ä¸é¡¯è‘—\n")
        
        f.write("\n4. **å¯¦å‹™å•Ÿç¤º**: é“å¾·åˆ¤æ–·å—å¤šé‡å› ç´ å½±éŸ¿ï¼Œå–®ä¸€è®Šæ•¸çš„é æ¸¬åŠ›æœ‰é™\n")
        
    print(f"âœ… æ‘˜è¦å ±å‘Š: {report_file}")


def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    print("\n" + "=" * 70)
    print("ğŸ“Š MIT Moral Machine - é‚è¼¯è¿´æ­¸åˆ†æ (Chapter 4.2)")
    print("=" * 70)
    
    # è¨­å®šæ—¥èªŒ
    logger = setup_logging()
    logger.info("é–‹å§‹åŸ·è¡Œé‚è¼¯è¿´æ­¸åˆ†æ...")
    
    try:
        # Step 1: è¼‰å…¥è³‡æ–™
        df = load_and_prepare_data()
        
        # Step 2: æº–å‚™é æ¸¬è®Šæ•¸
        df_model, predictor_vars = prepare_predictors(df)
        
        # Step 3: åŸ·è¡Œé‚è¼¯è¿´æ­¸
        results = run_main_logistic_regression(df_model, predictor_vars)
        
        # Step 4: è§£é‡‹çµæœ
        interpretation = interpret_results(results)
        
        # Step 5: ç”Ÿæˆå ±å‘Š
        generate_summary_report(results, interpretation)
        
        # å®Œæˆ
        print("\n" + "=" * 70)
        print("âœ… é‚è¼¯è¿´æ­¸åˆ†æå®Œæˆï¼")
        print("=" * 70)
        print("\nğŸ“Š å·²ç”¢ç”Ÿä»¥ä¸‹è¼¸å‡º:")
        print("  ã€è¡¨æ ¼ã€‘")
        print("  - outputs/tables/chapter4/logistic_regression_coefficients.csv")
        print("  - outputs/tables/chapter4/logistic_regression_vif.csv")
        print("  - outputs/tables/chapter4/logistic_regression_model_summary.csv")
        print("  - outputs/tables/chapter4/logistic_regression_hosmer_lemeshow.csv")
        print("\n  ã€åœ–è¡¨ã€‘")
        print("  - outputs/figures/chapter4_inference/logistic_coefficients_plot.html")
        print("  - outputs/figures/chapter4_inference/logistic_odds_ratio_plot.html")
        print("\n  ã€å ±å‘Šã€‘")
        print("  - report/drafts/chapter4_section2_logistic_regression.md")
        print("  - outputs/logs/logistic_regression.log")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥: python scripts/11_interaction_analysis.py")
        print("=" * 70 + "\n")
        
        logger.info("é‚è¼¯è¿´æ­¸åˆ†æå®Œæˆ")
        
    except Exception as e:
        logger.error(f"åŸ·è¡Œå¤±æ•—: {e}", exc_info=True)
        print(f"\nâŒ éŒ¯èª¤: {e}")
        raise


if __name__ == '__main__':
    main()